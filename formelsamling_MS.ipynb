{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c6d9be",
   "metadata": {},
   "source": [
    "# **Equations for multivariat statistics cheat sheet**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96bedca",
   "metadata": {},
   "source": [
    "### **Week 1 lecture A**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05161d1",
   "metadata": {},
   "source": [
    "##### **Multivariate normal or gaussian distribution (slide 45)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b49d6c",
   "metadata": {},
   "source": [
    "$p$-dimensional random variable:\n",
    "$$\n",
    "X = \\begin{bmatrix} X_1 \\\\ \\vdots \\\\ X_p \\end{bmatrix} \\in N_p(\\mu, \\Sigma)\n",
    "$$\n",
    "\n",
    "Mean value or expectation:\n",
    "$$\n",
    "\\mu = E(X) = \\begin{bmatrix} E(X_1) \\\\ \\vdots \\\\ E(X_p) \\end{bmatrix} = \\begin{bmatrix} \\mu_1 \\\\ \\vdots \\\\ \\mu_p \\end{bmatrix}\n",
    "$$\n",
    "Dispersion or variance matrix:\n",
    "$$\n",
    "\\Sigma =D(X) = \\begin{bmatrix} V(X_1) & \\dots & Cov(X_1, X_p) \\\\ \\vdots & \\ddots & \\vdots \\\\ Cov(X_p, X_1) & \\vdots & V(X_p) \\end{bmatrix}= \\begin{bmatrix} \\sigma_1^2 & \\dots & \\sigma_1 \\sigma_p \\rho_{1p} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\sigma_p \\sigma_1 \\rho_{p1} & \\dots & \\sigma_p^2 \\end{bmatrix}\n",
    "$$\n",
    "Frequency or density function:\n",
    "$$\n",
    "f(x) = \\frac{1}{\\sqrt{(2\\pi)}^p \\sqrt{\\text{det}{\\Sigma}}} \\exp \\left( -\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right)\n",
    "$$\n",
    "Contour lines that are ellipsoids with main axes given by eigenvectors of the variance matrix:\n",
    "$$\n",
    "f(x) = x \\Leftrightarrow (x-\\mu)^T \\Sigma^{-1}(x-\\mu) = k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df32389",
   "metadata": {},
   "source": [
    "##### **Estimation of paramters (slides 46-47)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94936c9c",
   "metadata": {},
   "source": [
    "The mean for the $i$'th observation:\n",
    "$$\n",
    "\\hat{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i\n",
    "$$\n",
    "The empirical variance-covariance matrix:\n",
    "$$\n",
    "S = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\hat{X})(X_i - \\hat{X})^T = \\frac{1}{n-1} \\Sigma_{i=1}^nX_iX_i^T - \\frac{n}{n-1} \\hat{X}\\hat{X}^T\n",
    "$$\n",
    "Other formulas for mean and dispersion:\n",
    "$$\n",
    "\\hat{X} = \\frac{1}{n} X^T \\begin{bmatrix} 1 \\\\ \\vdots \\\\ 1 \\end{bmatrix} = \\frac{1}{n} X^T 1\n",
    "$$\n",
    "For variance:\n",
    "$$\n",
    "(n-1)S = \\sum_{i=1}^{n} (X_i - \\hat{X})(X_i - \\hat{X})^T = X^TX - n \\hat{X}\\hat{X}^T = X^TX - \\frac{1}{n} X^T 11^TX\n",
    "$$\n",
    "Correlation matrix:\n",
    "$$\n",
    "\\rho_{ij} = \\frac{Cov(X_i, X_j)}{\\sqrt{V(X_i)} \\sqrt{V(X_j)}} = \\frac{\\sigma_{ij}}{\\sigma_i \\sigma_j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72959fd7",
   "metadata": {},
   "source": [
    "##### **Summary of calculation rules for univariate (slide 54):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b488e",
   "metadata": {},
   "source": [
    "Mean rules:\n",
    "$$\n",
    "E[a+bX] = a+bE[X]\n",
    "$$\n",
    "$$\n",
    "E[X+Y] = E[X] + E[Y]\n",
    "$$\n",
    "\n",
    "Variance rules:\n",
    "$$\n",
    "V[a+bX] = b^2V[X]\n",
    "$$\n",
    "$$\n",
    "V[X+Y] = V[X] + V[Y] + 2Cov(X,Y)\n",
    "$$\n",
    "Variance if $X$ and $Y$ are independent:\n",
    "$$\n",
    "V[X+Y] = V[X] + V[Y]\n",
    "$$\n",
    "\n",
    "Covariance rules:\n",
    "$$\n",
    "Cov[X,X] = V[X]\n",
    "$$\n",
    "$$\n",
    "Cov[X,Y] = Cov[Y,X]\n",
    "$$\n",
    "$$\n",
    "Cov[aX+bX] = abCov[X,Y]\n",
    "$$\n",
    "$$\n",
    "Cov[X, Y+Z] = Cov[X,Y] + Cov[X,Z]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b61de0",
   "metadata": {},
   "source": [
    "##### **Summary of calculation rules for multivariate (slide 54):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af731c5a",
   "metadata": {},
   "source": [
    "Mean rules:\n",
    "$$\n",
    "E[A+X] = A + E[X]\n",
    "$$\n",
    "$$\n",
    "E[AX] = A E[X]\n",
    "$$\n",
    "$$\n",
    "E[XB] = E[X] B\n",
    "$$\n",
    "$$\n",
    "E[X+Y] = E[X] + E[Y]\n",
    "$$\n",
    "\n",
    "Variance rules:\n",
    "$$\n",
    "V[A+BX] = B V[X] B^T\n",
    "$$\n",
    "$$\n",
    "V[AX] = A V[X] A^T\n",
    "$$\n",
    "$$\n",
    "V[X+Y] = V[X] + V[Y]+Cov[X,Y] + Cov[X,Y]^T\n",
    "$$\n",
    "\n",
    "Variance if $X$ and $Y$ are independent:\n",
    "$$\n",
    "V[X+Y] = V[X] + V[Y]\n",
    "$$\n",
    "\n",
    "Covariance rules:\n",
    "$$\n",
    "Cov[X,X] = V[X]\n",
    "$$\n",
    "$$\n",
    "Cov[X,Y] = Cov[Y,X]^T\n",
    "$$\n",
    "$$\n",
    "Cov[AX,BY] = A Cov[X,Y] B^T\n",
    "$$\n",
    "$$\n",
    "Cov[X, Y+Z] = Cov[X,Y] + Cov[X,Z]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46a76a",
   "metadata": {},
   "source": [
    "##### **Conditional distributions (slide 71):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d3e9c1",
   "metadata": {},
   "source": [
    "Mean formula if $(X_1, X_2)$ are multivariate normal and $\\mathbf{L}(X_1|X_2=x_2)$ are all normal for all values of $x_2$:\n",
    "$$\n",
    "E(X_1|X_2=x_2) = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (x_2 - \\mu_2)\n",
    "$$\n",
    "Variance formula:\n",
    "$$\n",
    "V(X_1|X_2=x_2)= \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21}\n",
    "$$\n",
    "With:\n",
    "$$\n",
    "X \\sim N_p (\\mu, \\Sigma), \\quad X= \\begin{bmatrix} X_1 \\\\ X_2 \\end{bmatrix}, \\quad \\mu = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\end{bmatrix}, \\quad \\Sigma = \\begin{bmatrix} \\Sigma_{11} & \\Sigma_{12} \\\\ \\Sigma_{21} & \\Sigma_{22} \\end{bmatrix}\n",
    "$$\n",
    "Variance $\\Sigma_{11}-\\Sigma_{12}\\Sigma_{22}^{-1}\\Sigma_{21}$ does not depend on the value of $x_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9416ff94",
   "metadata": {},
   "source": [
    "### **Week 2 lecture B**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05de9f4",
   "metadata": {},
   "source": [
    "##### **Formula for two dimensional normal distribution (slide 22):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55b7215",
   "metadata": {},
   "source": [
    "If we have a two-dimensional normal distribution $\\begin{bmatrix} X_1 \\\\ X_2 \\end{bmatrix} \\sim N_2 \\left( \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\end{bmatrix}, \\begin{bmatrix} \\sigma_1^2 & \\sigma_{12} \\\\ \\sigma_{21} & \\sigma_2^2 \\end{bmatrix} \\right)$ with $\\rho = Cor(X_1, X_2).\n",
    "\n",
    "Then expectation:\n",
    "$$\n",
    "E(X_1|X_2=x_2) = \\mu_1 + \\frac{\\sigma_{12}}{\\sigma_2^2} (X_2 - \\mu_2) = \\mu_1 + \\rho \\frac{\\sigma_1}{\\sigma_2} (X_2 - \\mu_2)\n",
    "$$\n",
    "\n",
    "The variance:\n",
    "$$\n",
    "V(X_1|X_2=x_2) = \\sigma_1^2 - \\frac{\\sigma_{12}^2}{\\sigma_2^2} = \\sigma_1^2 (1-\\rho^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95833e",
   "metadata": {},
   "source": [
    "##### **Formula for partial correlation coefficient (slide 25):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41a9496",
   "metadata": {},
   "source": [
    "Partial correlation between some variables given others is:\n",
    "$$\n",
    "\\rho_{ij|k} = \\frac{\\rho_{ij} - \\rho_{ik}\\rho_{jk}}{\\sqrt{(1-\\rho_{ik}^2)(1-\\rho_{jk}^2)}}\n",
    "$$\n",
    "From successive conditioning:\n",
    "$$\n",
    "\\rho_{ij|kl} = \\frac{\\rho_{ij|k} - \\rho_{il|k}\\rho_{jl|k}}{\\sqrt{(1-\\rho_{il|k}^2)(1-\\rho_{jl|k}^2)}}\n",
    "$$\n",
    "$$\n",
    "= \\frac{Cov(X_i, X_j|X_k)}{\\sqrt{Var(X_i|X_k)Var(X_j|X_k)}}\n",
    "$$\n",
    "THE OTHER FORMULA is if you have the conditional covariance matrix $V(Y|X)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e424f27",
   "metadata": {},
   "source": [
    "##### **Multiple correlation coefficient (slide 33-35):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e6c05",
   "metadata": {},
   "source": [
    "We have:\n",
    "$$\n",
    "\\rho_{y_i|x}= \\frac{\\sqrt{\\sigma_i^T\\Sigma_{xx}^{-1}\\sigma_i}}{\\sqrt{\\sigma_{ii}}}\n",
    "$$\n",
    "With:\n",
    "$$\n",
    "\\Sigma_i = \\begin{bmatrix} \\sigma_{ii} & \\sigma_i^T \\\\ \\sigma_i & \\Sigma_{xx} \\end{bmatrix}\n",
    "$$\n",
    "Then:\n",
    "$$\n",
    "1-\\rho^2_{y_i|x} = \\frac{\\text{det}(\\Sigma_i)}{\\sigma_{ii} \\text{det}(\\Sigma_{xx})} = \\frac{V(Y_i|X)}{V(Y_i)}\n",
    "$$\n",
    "(this is theorem 1.42 in the book)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca91845",
   "metadata": {},
   "source": [
    "##### **Multiple correlation $F$-statistic (slide 39):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e35a92",
   "metadata": {},
   "source": [
    "Formula based on $n$ observations:\n",
    "$$\n",
    "\\frac{R^2}{1-R^2} \\cdot \\frac{n-(p-m)-1}{p-m} \\sim F(p-m, n-(p-m)-1)\n",
    "$$\n",
    "IF $\\rho_{y_i|x} = 0$ (null hypothesis) holds for the $F$-distribution, we can conclude that the model is appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa389f5a",
   "metadata": {},
   "source": [
    "### **Week 3 lecture C**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c56e5d",
   "metadata": {},
   "source": [
    "##### **Formula for $100(1-\\alpha)\\%$ confidence ellpsoid for unknown mean (slide 6):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e892563",
   "metadata": {},
   "source": [
    "##### **Partial correlation coefficient III formula for $t$-test (slide 13):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f7ef9a",
   "metadata": {},
   "source": [
    "This is a formula for estimation of parameters  :\n",
    "$$\n",
    "\\{\\mu | (\\mu - \\bar{x})^Ts^{-1} (\\mu-\\bar{x}) \\leq \\frac{p(n-p)}{n-(p-1)} F(p, n-p)_{1-\\alpha} \\}\n",
    "$$\n",
    "\n",
    "Formula for coming observation $x$ (also $100(1-\\alpha)\\%$ confidence ellipsoid):\n",
    "$$\n",
    "\\{x | (x - \\bar{x})^Ts^{-1}(x-\\bar{x}) \\leq \\frac{p(n+1)(n-1)}{n(n-p)} F(p, n-p)_{1-\\alpha} \\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b709ee",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "\\frac{R}{\\sqrt{1-R^2}}\\sqrt{n-2-(p-m)} \\sim t(n-2-(p-m))\n",
    "$$\n",
    "REMEMBER this is for the standard relationship between a partial correlatio, and again $p$ total variables in full model and $m$ is number in reduced and $R$ is partial correlation coefficient between two models, $p-m$ is the number of variables being tested.\n",
    "\n",
    "USE THIS if $R$ is the sample partial correlation between the two variables after conditioning on the control variables and the df are computed correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8ec51",
   "metadata": {},
   "source": [
    "##### **Formula for squared multiple correlation (slide 17):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904cc42",
   "metadata": {},
   "source": [
    "Formula from book:\n",
    "$$\n",
    "1-\\rho^2_{y_1|x} = \\frac{\\text{det}\\Sigma_i}{\\sigma_{ii} \\text{det}\\Sigma_{xx}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161743b2",
   "metadata": {},
   "source": [
    "Formula is (ONLY USE IF SYMMETRIC VARIANCE LIKE SAME NUMBER IN THE DIAGONAL):\n",
    "$$\n",
    "\\rho^2_{1|ab} = \\Sigma_{1, ab} \\Sigma_{ab, ab}^{-1} \\Sigma_{ab, 1}\n",
    "$$\n",
    "Here, $1$, $a$, and $b$ are indices for variables in matrices.\n",
    "\n",
    "IF NOT symmetric variance matrix, use:\n",
    "$$\n",
    "\\rho^2_{1|ab} = \\Sigma_{1, ab} \\Sigma_{ab, ab}^{-1} \\Sigma_{ab, 1} \\cdot \\frac{1}{\\sigma_{11}}\n",
    "$$\n",
    "So if else, then remember to divide with the variance of variable 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b68d87c",
   "metadata": {},
   "source": [
    "##### **$t$-test (t-test) for mula for a simple (or multiple) linear regression estimated by OLS that intercept is zero (exam 2011 problem 1):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fc57e6",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "t = \\frac{\\hat{\\alpha}-0}{SE(\\hat{\\alpha})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4df9d1",
   "metadata": {},
   "source": [
    "##### **The standard t–test for a partial correlation $r$ conditioning on $k$ control variables (exam 2011 problem 5):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c14e8f",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "t = \\frac{r \\sqrt{n-k-2}}{\\sqrt{1-r^2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98079acc",
   "metadata": {},
   "source": [
    "##### **Formula for test of $k-m$ smallest eigenvalues in the correlation matrix (slide 69):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc5f88",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "Z_2 = -n \\log \\frac{\\hat{\\lambda}_{m+1} \\dots \\hat{\\lambda}_k}{\\hat{\\lambda}_*^{k-m}} = -n(k-m)\\left( \\log G - \\log(\\hat{\\lambda}_*) \\right)\n",
    "$$\n",
    "In this formula, the numerator is the geometric mean $G$ and the denominator is the arithmetic mean $\\hat{\\lambda}_*$ given as:\n",
    "$$\n",
    "\\hat{\\lambda}_* = \\frac{k-\\hat{\\lambda}_1 - \\dots - \\hat{\\lambda}_m}{k-m} = \\frac{\\hat{\\lambda}_{m+1} + \\dots + \\hat{\\lambda}_k}{k-m}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce756dc",
   "metadata": {},
   "source": [
    "BUT use the standard Bartlett-type chi-square DF for testing that the last ($q$) eigenvalues are equal:\n",
    "\n",
    "$$\n",
    "\\text{df} = \\tfrac{1}{2}(q-1)(q+2),\n",
    "$$\n",
    "\n",
    "Where $q=k-m$ is the number of smallest eigenvalues being tested\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c9aae",
   "metadata": {},
   "source": [
    "Use this test when testing if all eigenvalues are equal:\n",
    "$$\n",
    "\\frac{1}{2}(k(k-1))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0b67b",
   "metadata": {},
   "source": [
    "### **Week 4 lecture D**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486e779d",
   "metadata": {},
   "source": [
    "**Formulas for factor loadings and model assumptions:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a943f5b4",
   "metadata": {},
   "source": [
    "Formula book:\n",
    "$$\n",
    "V(X) = R = V(AF+G) = AA^T + \\Delta\n",
    "$$\n",
    "$$\n",
    "V(X_i) = a_{i1}^2+\\dots + a_{im}^2+ \\delta_i = h_i^2 + \\delta_i = 1\n",
    "$$\n",
    "$$\n",
    "Cov(X, F) = Cov(AF + G, F) = A\n",
    "$$\n",
    "$$\n",
    "Cov(X_i, F_j) = Corr(Cov(X_i, F_j)) = a_{ij}\n",
    "$$\n",
    "$$\n",
    "V\\begin{bmatrix} X \\\\ F \\end{bmatrix} = \\begin{bmatrix} R & A \\\\ A^T & I \\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "V(X|F) = R-AA^T = \\Delta\n",
    "$$\n",
    "$$\n",
    "V\\begin{bmatrix} X_i \\\\F \\end{bmatrix} = \\begin{bmatrix} 1 & [a_{i1} \\dots a_{im}] \\\\  [a_{i1} \\\\ \\vdots \\\\ a_{im}] & I \\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "V(X_i|F) = 1-[a_{i1} \\cdots a_{im}]I^{-1} \\begin{bmatrix} a_{i1} \\\\ \\vdots \\\\ a_{im} \\end{bmatrix} = 1 - (a_{i1}^2 + \\dots + a_{im}^2) = \\delta_i\n",
    "$$\n",
    "$$\n",
    "V(X_i) - V(X_i|F) = a_{i1}^2 + \\dots + a_{im}^2 = h_i^2\n",
    "$$\n",
    "REMEMBER:\n",
    "$$\n",
    "E(X_1|X_2 = x_2) = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (x_2 - \\mu_2)\n",
    "$$\n",
    "$$\n",
    "V(X_1|X_2 = x_2) = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10309157",
   "metadata": {},
   "source": [
    "##### **Formula for reconstructing the factor scores (slide 48):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f27cec",
   "metadata": {},
   "source": [
    "Formulas:\n",
    "$$\n",
    "V(X_i|F_j) = 1-a_{ij}^2\n",
    "$$\n",
    "$$\n",
    "V(X_1|F_j) + \\dots + V(X_k|F_j) = k-(a_{1j}^2 + \\dots + a_{kj}^2)\n",
    "$$\n",
    "$$\n",
    "\\Sigma V(X_i)- \\{V(X_1|F_j) + \\dots + V(X_k|F_j)\\} = (a_{1j}^2 + \\dots + a_{kj}^2)\n",
    "$$\n",
    "$$\n",
    "V \\begin{bmatrix} F \\\\ X \\end{bmatrix} = \\begin{bmatrix} I & A^T \\\\ A & R \\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "E(F|X=x) = \\mu_F + A^T R^{-1}(x-\\mu_X) = A^TR^{-1} x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a168c719",
   "metadata": {},
   "source": [
    "##### **PCA formula (slide 49):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43a9428",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "\\Sigma = P \\Lambda P^T = P \\Lambda^{1/2} \\Lambda^{1/2} P^T = P \\Lambda^{1/2} (P \\Lambda^{1/2})^T = AA^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebed2bb6",
   "metadata": {},
   "source": [
    "##### **Formula for communalities (used in ex 7.5):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cfac0a",
   "metadata": {},
   "source": [
    "If we have something defined as, which is called the factor model:\n",
    "$$\n",
    "X = \\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\end{bmatrix} = \\begin{bmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\\\ a_{31} & a_{32} \\end{bmatrix} \\begin{bmatrix} F_1 \\\\ F_2 \\end{bmatrix} + \\begin{bmatrix} G_1 \\\\ G_2 \\\\ G_3 \\end{bmatrix} = AF + G\n",
    "$$\n",
    "Then the communalities are given by:\n",
    "$$\n",
    "h_i^2 = a_{i1}^2 + a_{i2}^1\n",
    "$$\n",
    "So like for this example we have $3$ communalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aa2319",
   "metadata": {},
   "source": [
    "##### **Formula for dispersion for factor model (used in ex 7.5):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06f7e85",
   "metadata": {},
   "source": [
    "The matrix $R$, given as:\n",
    "$$\n",
    "R = AA^T+\\Delta\n",
    "$$\n",
    "Here, $\\Delta$ is the diagonal matrix of $G$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a86a1f5",
   "metadata": {},
   "source": [
    "##### **Uniqueness of a variable formula in factor analysis (exam 22 problem 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71bfdfd",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "i = 1- \\sum_{j=1}^{m} a_{ij}^2\n",
    "$$\n",
    "So this is, for instance, when we have maybe $j$ number of rotated factors and a table with all variables, then for a certain variable, we just take the number for each factor, square it, sum them up and subtract from $1$ to get the uniqueness for that variable.\n",
    "\n",
    "Professor also calls it \"simply just $1$ minus the communality\" so uniqueness is variance in variable $i$ not explained by common factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9dd54",
   "metadata": {},
   "source": [
    "##### **Explained variance in variable $i$ (communality):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ba504",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "h_i^2 = \\sum_{j=1}^{m} a_{ij}^2\n",
    "$$\n",
    "Which is for variance in variable $i$ explained by common factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76702691",
   "metadata": {},
   "source": [
    "##### **Explained fraction of variance of a variable in no intercept regression (exam 2024 problem 1):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595039b9",
   "metadata": {},
   "source": [
    "For no intercept regression we have:\n",
    "$$\n",
    "\\hat{\\beta} = (X^TX)^{-1}X^Ty\n",
    "$$\n",
    "Explained fraction of variance is:\n",
    "$$\n",
    "R^2 = \\frac{y^T X (X^TX)^{-1} X^T y}{y^T y}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ed9be",
   "metadata": {},
   "source": [
    "##### **Proportion of total variance explained by factor $j$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89679c4d",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "V(F_j) = \\sum_{i=1}^k a_{ij}^2 \\cdot \\frac{1}{k}\n",
    "$$\n",
    "Where, $k$ is the number of variables. This is PROPORTION (OR FRACTION) of total variance (across all variables) explained by factor $j$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebced94f",
   "metadata": {},
   "source": [
    "### **Week 5 lecture E**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449d3e1",
   "metadata": {},
   "source": [
    "##### **Formulas for the factor model (slide 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d79875",
   "metadata": {},
   "source": [
    "First the factor model is:\n",
    "$$\n",
    "[X_1 \\; X_2 \\; \\cdots \\; X_n]^T = A [F_1 \\; F_2 \\; \\cdots \\; F_n]^T + [G_1 \\; G_2 \\; \\cdots \\; G_n]^T\n",
    "$$\n",
    "And:\n",
    "$$\n",
    "X = AF + G\n",
    "$$\n",
    "For the expression below, data has vairance 1, so the data is normalized and we use correlation matrix.\n",
    "$$\n",
    "V(X) = R = \\begin{bmatrix} 1 & \\dots & \\rho_{1k} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\rho_{k1} & \\dots & 1 \\end{bmatrix} \n",
    "$$\n",
    "The factors are uncorrelated below:\n",
    "$$\n",
    "V(F) = I = I_m = \\begin{bmatrix} 1 & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & 1 \\end{bmatrix}\n",
    "$$\n",
    "The unique factors are uncorrelated below:\n",
    "$$\n",
    "V(G) = \\Delta = \\begin{bmatrix} \\delta_1 & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & \\delta_k \\end{bmatrix}\n",
    "$$\n",
    "$F$ ang $G$ are uncorrelated:\n",
    "$$\n",
    "Cov(F,G) = 0 = \\begin{bmatrix} 0 & \\dots & 0 \\\\ \\vdots & \\ddots & \\vdots \\\\ 0 & \\dots & 0 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfbb88",
   "metadata": {},
   "source": [
    "##### **Testing the factor structure formula (slide 19):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff9a17",
   "metadata": {},
   "source": [
    "Test statistic:\n",
    "$$\n",
    "Z = \\left( n-1 - \\frac{1}{6}{2k+5}-\\frac{2}{3}m\\right) \\log \\left( \\frac{|\\hat{A}\\hat{A}^T + \\hat{\\Delta}|}{|R|} \\right)\n",
    "$$\n",
    "Which asymptotically follows a $\\chi^2\\left( \\frac{1}{2}((k-m)^2-k-m)\\right)$ distribution where $n$ is observations, $k$ is variables and $m$ is factors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951102b4",
   "metadata": {},
   "source": [
    "##### **Squared correlation formula (slide 28-31):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5943a4",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "\\rho^2 = \\frac{\\Sigma_{YX}\\Sigma_{XX}^{-1}\\Sigma_{XY}}{\\sigma_Y^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87b9e89",
   "metadata": {},
   "source": [
    "##### **(MORE FORMULAS TO BE ADDED)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f3aed5",
   "metadata": {},
   "source": [
    "### **Week 6 lecture F**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1d6200",
   "metadata": {},
   "source": [
    "##### **Canonical correlation formulas (slide 31):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a5cb60",
   "metadata": {},
   "source": [
    "Formula for covariance between a linear combination $a$ of $Y$ and a linear combination $b$ of $X$:\n",
    "$$\n",
    "Cov(a^TY, b^TX) = a^T \\Sigma_{YX} b\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224c6228",
   "metadata": {},
   "source": [
    "The correlation is:\n",
    "$$\n",
    "Cor(a^TY, b^TX) = \\frac{a^T \\Sigma_{YX} b}{\\sqrt{a^T \\Sigma_{YY} a} \\sqrt{b^T \\Sigma_{XX} b}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ae5bc",
   "metadata": {},
   "source": [
    "Formula if you want to find lienar combinations so that the correlation between the linear combinations is maximal then solve:\n",
    "$$\n",
    "\\max_{a,b}a^T \\Sigma_{YX} b \\quad \\text{under the constraints} \\quad a^T \\Sigma_{YY} a = 1, \\quad b^T \\Sigma_{XX} b = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed152b",
   "metadata": {},
   "source": [
    "##### **Optimal discriminator formula (from ex 6.2 and slide 56):**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cd1d5",
   "metadata": {},
   "source": [
    "Formula to see whcih groups are most influential and the strongest variables:\n",
    "$$\n",
    "\\delta = \\Sigma^{-1}(\\mu_1 - \\mu_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82be15",
   "metadata": {},
   "source": [
    "##### **Bayes solution formula for a region (from slide 34 and ex 6.2):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616a164f",
   "metadata": {},
   "source": [
    "Formula used in exercise\n",
    "$$\n",
    "\\frac{f_1(\\mathbf{x})}{f_2(\\mathbf{x})} \\ge \\frac{L_{21} p_2}{L_{12} p_1}\n",
    "$$\n",
    "\n",
    "For the full one:\n",
    "$$\n",
    "R_1 = \\left\\{ x | \\frac{f_1(\\mathbf{x})}{f_2(\\mathbf{x})} \\ge \\frac{L_{21} p_2}{L_{12} p_1} \\right\\}    \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b836293",
   "metadata": {},
   "source": [
    "##### **Bayes solution full derivation (from ex 6.2):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9481b66",
   "metadata": {},
   "source": [
    "Formula used in exercise:\n",
    "$$\n",
    "\\frac{f_1(\\mathbf{x})}{f_2(\\mathbf{x})} \\ge \\frac{L_{21} p_2}{L_{12} p_1}\n",
    "$$\n",
    "Then after substitution and simplification, the rule becomes:\n",
    "$$\n",
    "\\mathbf{x}^T \\Sigma^{-1}(\\mu_1 - \\mu_2) - \\frac{1}{2} (\\mu_1^T \\Sigma^{-1} \\mu_1 - \\mu_2^T \\Sigma^{-1} \\mu_2) \\ge \\ln \\left(\\frac{L_{21} p_2}{L_{12} p_1}\\right)\n",
    "$$\n",
    "Basically we have this, and this one has a constant $c$ part, which we must calculate:\n",
    "$$\n",
    "\\mathbf{x}^T \\hat{\\Sigma}^{-1} (\\hat{\\mu}_1 - \\hat{\\mu}_2) \\underbrace{- \\frac{1}{2} \\hat{\\mu}_1^T \\hat{\\Sigma}^{-1} \\hat{\\mu}_1 + \\frac{1}{2} \\hat{\\mu}_2^T \\hat{\\Sigma}^{-1} \\hat{\\mu}_2}_{\\text{The constant threshold part (c)}}\n",
    "$$\n",
    "Hence we need:\n",
    "$$\n",
    "c = -\\frac{1}{2} \\hat{\\mu}_2^T \\hat{\\Sigma}^{-1} \\hat{\\mu}_2 + \\frac{1}{2} \\hat{\\mu}_1^T \\hat{\\Sigma}^{-1} \\hat{\\mu}_1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb22f61",
   "metadata": {},
   "source": [
    "##### **Formula for bayes classification rule corresponding to using prior probabilites (used in ex 6.2):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c4f4ab",
   "metadata": {},
   "source": [
    "From above we have (EQUAL PRIORS):\n",
    "$$\n",
    "c = -\\frac{1}{2} \\mu_2^T \\Sigma^{-1} \\mu_2 + \\frac{1}{2} \\mu_1^T \\Sigma^{-1} \\mu_1\n",
    "$$\n",
    "This constant $c$ is the scalar part of the discriminant function assuming equal prior probabilities ($\\pi_1 = \\pi_2 = 0.5$) and equal costs.\n",
    "\n",
    "But now we have to adjust the decision rule since the prior probabilities ($\\pi_k$) have changed. The change in priors introduces an extra term into the classification boundary equation. This term is added to the constant $c$ you calculated in exercise 3.\n",
    "\n",
    "The general decision rule boundary, comparing class 1 and class 2, is where the linear discriminant function (LDF) equals the log-ratio of the priors and costs gives as:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2) = -\\underbrace{\\frac{1}{2} (\\boldsymbol{\\mu}_1^T \\mathbf{\\Sigma}^{-1} \\boldsymbol{\\mu}_1 +\\boldsymbol{\\mu}_2^T \\mathbf{\\Sigma}^{-1} \\boldsymbol{\\mu}_2)}_{\\text{part from ex. 3 (c)}} + \\underbrace{\\ln \\left(\\frac{L_{21} \\pi_2}{L_{12} \\pi_1}\\right)}_{\\text{new term for ex. 4}}\n",
    "$$\n",
    "\n",
    "The new decision rule is to classify $\\mathbf{x}$ to group 1 if:\n",
    "$$\n",
    "\\mathbf{x}^T \\mathbf{\\Sigma}^{-1} (\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_2) > c_{\\text{new}}\n",
    "$$\n",
    "\n",
    "Where the new threshold $c_{\\text{new}}$ is:\n",
    "\n",
    "$$\\mathbf{c}_{\\text{new}} = \\left(-\\frac{1}{2} \\mu_1^T \\Sigma^{-1} \\mu_1 + \\frac{1}{2} \\mu_2^T \\Sigma^{-1} \\mu_2\\right) + \\ln \\left(\\frac{\\pi_2}{\\pi_1}\\right)$$\n",
    "\n",
    "EXAMPLE ON HOW TO FIND $\\pi$ values:\n",
    "\n",
    "Not to find the two $\\pi$ values, we know that group 1 (class 10 or whatever) has 493 pixels while the other has 73 pixels. These are our proportions, hence:\n",
    "$$\n",
    "\\pi_1 = \\frac{493}{493 + 73} \\approx 0.871 \\quad \\text{and} \\quad \\pi_2 = \\frac{73}{493 + 73} \\approx 0.129\n",
    "$$\n",
    "Now we just insert everything in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e28f6",
   "metadata": {},
   "source": [
    "##### **Discrimination with unknown parameters (slide 54):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e58c48",
   "metadata": {},
   "source": [
    "Estimated decision rule:\n",
    "$$\n",
    "x^T\\hat{\\Sigma}^{-1} (\\hat{\\mu}_1 - \\hat{\\mu}_2) - \\frac{1}{2} \\hat{\\mu}_1^T \\hat{\\Sigma}^{-1} \\hat{\\mu}_1 + \\frac{1}{2} \\hat{\\mu}_2^T \\hat{\\Sigma}^{-1} \\hat{\\mu}_2\n",
    "$$\n",
    "Here, for large sample sizes we can use distribution of $Z$ from theorem $5.8$ to estimate the separating hyperplane.\n",
    "\n",
    "Mahanalobis distance:\n",
    "$$\n",
    "\\Delta^2_{\\hat{\\Sigma^{-1}}}(\\hat{\\mu}_1, \\hat{\\mu}_2) = \\| \\hat{\\mu}_1 - \\hat{\\mu}_2 \\|^2_{\\hat{\\Sigma^{-1}}} = (\\hat{\\mu}_1 - \\hat{\\mu}_2)^T \\hat{\\Sigma}^{-1} (\\hat{\\mu}_1 - \\hat{\\mu}_2)\n",
    "$$\n",
    "Formula for how $D^2$ is linked in distribution to Hotellings $T^2$ statistic:\n",
    "$$\n",
    "D=\\frac{n_1+n_2}{n_1 n_2} T^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0946165",
   "metadata": {},
   "source": [
    "### **Week 7 lecture G**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1c0ee6",
   "metadata": {},
   "source": [
    "##### **Formula for leasts squares estimator (used in ex 3.1):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4439d4bb",
   "metadata": {},
   "source": [
    "Formula for maximum likelihood estimator in multiple linear regression:\n",
    "$$\n",
    "\\hat{\\beta} = (X^TX)^{-1}X^Ty\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2589dcc8",
   "metadata": {},
   "source": [
    "Estimated error:\n",
    "$$\n",
    "\\hat{\\epsilon} = y - X\\hat{\\beta}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfaf738",
   "metadata": {},
   "source": [
    "##### **Variance of the least squares estimator (exam 2022 problem 5):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90ad559",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "V(\\hat{\\beta}) = \\sigma^2 (X^TX)^{-1}\n",
    "$$\n",
    "THIS IS THE SAME FOR COVARIANCE ALSO, like covariance is in the off-diagonal elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f314d",
   "metadata": {},
   "source": [
    "##### **The Mahanalobis distance (slide 11):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ec3bf4",
   "metadata": {},
   "source": [
    "Formula for empirical Mahanalobis distance:\n",
    "$$\n",
    "D^2 = \\| \\hat{\\mu}_1 - \\hat{\\mu}_2 \\|^2_{\\hat{\\Sigma}^{-1}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122e9e1",
   "metadata": {},
   "source": [
    "##### **2-sample test in $p$ dimensions (slide 15):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfef1e97",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "D^2 = \\frac{n_1 n_2}{n_1+n_2}T^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a3861",
   "metadata": {},
   "source": [
    "##### **Formula for estimating residual error for a model (ex 3.1):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a4f8c",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "\\hat{\\sigma} = \\sqrt{\\frac{\\sum e^2_1}{n-k}}\n",
    "$$\n",
    "Here, $n$ is the number of observations, $k$ is the number of parameters, and $e$ are residuals which can be read on a summary R output.\n",
    "\n",
    "(NOTE $k$ often includes intecept, while $p$ does NOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c763c1da",
   "metadata": {},
   "source": [
    "### **Week 8 lecture H**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8d7ef",
   "metadata": {},
   "source": [
    "##### **(MORE FORMULAS TO BE ADDED)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1400a466",
   "metadata": {},
   "source": [
    "### **Week 9 lecture I**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8882004",
   "metadata": {},
   "source": [
    "##### **Formula for unbiased estimate (exam 2012 problem 5):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a138b3",
   "metadata": {},
   "source": [
    "The formula for $\\hat{\\sigma}^2$ is given as:\n",
    "$$\n",
    "\\hat{\\sigma}^2 = \\frac{(y-x\\hat{\\theta})'(y-x\\hat{\\theta})}{n-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829983fd",
   "metadata": {},
   "source": [
    "##### **(MORE FORMULAS TO BE ADDED)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cddd6c",
   "metadata": {},
   "source": [
    "### **Week 10 lecture J**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974c0801",
   "metadata": {},
   "source": [
    "##### **Formula for confidence inteval (exam 2007 problem 8):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fdd83e",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "[u+t(n-k)_{1-\\frac{\\alpha}{2}}s\\sqrt{c}, u+t(n-k)_{\\frac{\\alpha}{2}}s\\sqrt{c}]\n",
    "$$\n",
    "Here, $n$ is the number of observations and $k$ is the number of parameters (with intercept), $t(n-k)_{1-\\frac{\\alpha}{2}}$ is the $t$-value for the confidence level, $s$ is the estimated standard deviation of the residuals, and $c$ is given by:\n",
    "$$\n",
    "c = x_0^T (X^TX)^{-1} x_0\n",
    "$$\n",
    "Moreover, for instance, if we have $95\\%$ confidence interval, then $\\alpha = 0.05$ so inside R function we write `qt(0.975, df=n-k)` because $1-\\frac{\\alpha}{2} = 0.975$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c02f0",
   "metadata": {},
   "source": [
    "##### **Formula for reduced variance (exam 2008 problem 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d7adca",
   "metadata": {},
   "source": [
    "Formula (THIS IS FOR REGRESSION MODELS):\n",
    "$$\n",
    "R^2 = \\frac{SSR_{M2} - SSR_{M1}}{SSR_{M2}}\n",
    "$$\n",
    "This is specifically the reduced variance between two models $M1$ and $M2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b27c0f",
   "metadata": {},
   "source": [
    "##### **Formula for when asked to find test tastitic for hypothesis $R^2 = 0$ (exam 2008 problem 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997a33bd",
   "metadata": {},
   "source": [
    "This means that $H_0: \\beta_1 = \\beta_2 = 0$ is what we have to check for, aka to check whether the model explains any variance at all - then we are testing the null hypothesis that all regression coefficients (except the intercept) are zero.\n",
    "\n",
    "Formula is (AGAIN, IT IS TESTING FOR GLOBAL MODEL):\n",
    "$$\n",
    "F = \\frac{R^2/k}{(1-R^2)/(n-k-1)} \n",
    "$$\n",
    "Here, $k$ is the number of parameters (excluding intercept) and $n$ is the number of observations.\n",
    "\n",
    "OR THIS ONE, if we go from a model with more parameters to less parameters (reduced model):\n",
    "$$\n",
    "  F=\\frac{(SSE_{\\text{reduced}}-SSE_{\\text{full}})/q}{SSE_{\\text{full}}/(n-p_{\\text{full}})} \\sim F(q, n-p_\\text{full})\n",
    "$$\n",
    "With $q$ being number of restrictions (number of parameters in full model minus reduced model), and remember $p$ is with intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c06123",
   "metadata": {},
   "source": [
    "OR another testing wether some variables for full and reduced model contribue significantly to descriminating between two models:\n",
    "$$\n",
    "F = \\frac{N-p-1}{q} \\cdot \\frac{d_\\text{full}^2 - d_\\text{reduced}^2}{d_\\text{full}^2}\n",
    "$$\n",
    "Here, $d$ is distance for full and reduced model, here $N$ is not number of total observations but total number of observations in both groups, $p$ is number of parameters in full model, and $q$ is number of restrictions (number of parameters in full model minus reduced model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b93987",
   "metadata": {},
   "source": [
    "##### **Formula for $R^2=0$ hypethesis again, but based on the book (exam 2008 problem 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af08306",
   "metadata": {},
   "source": [
    "Theorem 1.45 in the book:\n",
    "$$\n",
    "\\frac{R^2}{1-R^2}\\frac{n-k-1}{k} \\sim F(k, n-k-1)\n",
    "$$\n",
    "Here, $k$ is the number of predictors (not including intercept) and $n$ is the number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491194f3",
   "metadata": {},
   "source": [
    "OR for $R^2=0$ but with $t$-test (also $F=t^2$) between correlation of $X$ and $Y$ (exam 2023 problem 3):\n",
    "$$\n",
    "t= \\frac{r}{\\sqrt{(1-r^2)}}\\sqrt{n-2} \\sim t(n-2)\n",
    "$$\n",
    "So with $n-2$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca4712",
   "metadata": {},
   "source": [
    "##### **(OVERALL for a SINGLE linear MODEL) $F$-statistic (exam 2008 problem 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46df8f5",
   "metadata": {},
   "source": [
    "How is usually is written:\n",
    "$$\n",
    "F(k, n-k-1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990cfc11",
   "metadata": {},
   "source": [
    "##### **(PARTIAL for TWO models) $F$-test for nested models (exam 2014 problem 4):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f7f6a",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "F(q, n - p_{\\text{full}}) \n",
    "$$\n",
    "Where $q$ is the number of restrictions (so difference between reduced and full model), $n$ is the number of observations, and $p_{\\text{full}}$ is the number of parameters in the full model (including intercept)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abcb06b",
   "metadata": {},
   "source": [
    "##### **Summary table for values where Cook's D for a model can be compared in a suitable percentage in a distribution (exam 2008 problem 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebca1d1",
   "metadata": {},
   "source": [
    "TABLE:\n",
    "\n",
    "| Model parameterization     |  $p$ (incl. intercept) | $n$  | Compare Cook’s D to $F(p, n−p)$    |\n",
    "| -------------------------- | ------------------- | -- | ----------------------------- |\n",
    "| Simple linear              | $2$                   | $n$  | $F(2, n−2)$                     |\n",
    "| Two predictors + intercept | $3$                   | $45$ | $F(3, 42)$                |\n",
    "| Big model with 10 params   | $10$                  | $n$  | $F(10, n−10)$                   |\n",
    "\n",
    "GENERAL formula for distribution of Cook's D:\n",
    "$$\n",
    "F(p, n-p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f1357",
   "metadata": {},
   "source": [
    "##### **Formular for testing if there is a difference in the intercept between three locations (exam 2008 problem 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27155e7",
   "metadata": {},
   "source": [
    "Formula with models inserted from the exercise:\n",
    "$$\n",
    "\\frac{[SS_{model}(M3)-SS_{model}(M1)]/ (df_{M3}-df_{M1})}{[SS_{residual}(M3)/df_{residual}(M3)]}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed2b8f",
   "metadata": {},
   "source": [
    "##### **Formula for Cook's distance (slide 54):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533880e4",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "D_i = \\frac{e^2_i}{p \\hat{\\sigma}^2} \\cdot \\frac{h_{ii}}{(1-h_{ii})^2}\n",
    "$$\n",
    "Note that Cook's distance is high when both the leverage $h_{ii}$ and the squared residual $e_i^2$ are high and $p$ is the number of parameters in the model (including intercept)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1748ac",
   "metadata": {},
   "source": [
    "Here, another formula:\n",
    "$$\n",
    "h_{ii} = X_i(X^TX)^{-1}X_i^T = \\|X_i\\|^2_{(X^TX)^{-1}}\n",
    "$$\n",
    "NOTE that leverage are hat values, and if a question asks for POTENTIAL to influence the model, then we look at leverage values. If they straight up asks for large influence, then we look at Cook's D values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd80f6",
   "metadata": {},
   "source": [
    "NOTE: the higher Cook's distance value is, the more influence the point (or variable) has on the overall regression fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bb0fd5",
   "metadata": {},
   "source": [
    "##### **Confidence interval and prediction interval formulas (from ex 4.3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e4f58",
   "metadata": {},
   "source": [
    "Confidence interval formula FOR REGRESSION:\n",
    "$$\n",
    "\\hat{y} \\pm t s \\sqrt{x_0^T (X^T X)^{-1} x_0}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ee80b",
   "metadata": {},
   "source": [
    "Prediction interval formula:\n",
    "$$\n",
    "\\hat{y} \\pm t s \\sqrt{1 + x_0^T (X^T X)^{-1} x_0}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee197a",
   "metadata": {},
   "source": [
    "TOTAL length of prediction interval:\n",
    "$$\n",
    "\\text{Length} = 2 \\cdot t_{1-\\alpha/2,n-k} \\cdot s \\sqrt{1 + x_0^T (X^T X)^{-1} x_0}.\n",
    "$$\n",
    "\n",
    "If we want the “half-length”, it is just:\n",
    "$$\n",
    "t_s \\sqrt{1 + x_0^T (X^TX)^{-1} x_0}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209df38d",
   "metadata": {},
   "source": [
    "##### **Formula for Hotelling's T-square in the one sample case (formula 61):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b9483",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "T^2 = n(\\bar{X} - \\mu)^T S^{-1} (\\bar{X} - \\mu)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168ce29e",
   "metadata": {},
   "source": [
    "##### **Notations for Hotelling's T-square in one sample case (slide 63):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033b257",
   "metadata": {},
   "source": [
    "Notations:\n",
    "$$\n",
    "\\bar{X} = \\frac{1}{n} \\sum_{i=1}^{n} X_i \\in N_p(\\mu, \\frac{1}{n}\\Sigma)\n",
    "$$\n",
    "$$\n",
    "\\bar{Y} = \\frac{1}{m} \\sum_{i=1}^{m} Y_i \\in N_p(\\nu, \\frac{1}{m}\\Sigma)\n",
    "$$\n",
    "$$\n",
    "S_1 = \\frac{1}{n-1}  \\sum_{i=1}^n (X_i - \\bar{X})(X_i - \\bar{X})^T\n",
    "$$\n",
    "$$\n",
    "S_2 = \\frac{1}{m-1}  \\sum_{i=1}^m (Y_i - \\bar{Y})(Y_i - \\bar{Y})^T\n",
    "$$\n",
    "$$\n",
    "S = \\frac{(n-1)S_1 + (m-1)S_2}{n+m-2} \\in W(n+m-2, \\frac{1}{n+m-2}\\Sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68195e49",
   "metadata": {},
   "source": [
    "##### **Other formula for Hotelling's T-square in one sample case (slide 64):**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe6b576",
   "metadata": {},
   "source": [
    "Other formula using notation above:\n",
    "$$\n",
    "T^2=\\frac{n_X n_Y}{n_X+n_Y}(\\bar X-\\bar Y)^\\top S^{-1}(\\bar X-\\bar Y),\n",
    "$$\n",
    "Here, $d^2 = (\\bar X-\\bar Y)^\\top S^{-1}(\\bar X-\\bar Y)$ is the squared Mahanalobis distance between the two sample means.\n",
    "\n",
    "Where the pooled covariance is\n",
    "$$\n",
    "S=\\frac{(n_X-1)S_X+(n_Y-1)S_Y}{n_X+n_Y-2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c217fec",
   "metadata": {},
   "source": [
    "##### **Formula to go from Hotelling's T-square to F-distribution (from ex 5.1):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485e67a",
   "metadata": {},
   "source": [
    "The conversion (two-sample case, pooled) is:\n",
    "$$\n",
    "F=\\frac{(n_X+n_Y-p-1)}{p(n_X+n_Y-2)}T^2  \\sim F(p, n_X+n_Y-p-1)\n",
    "$$\n",
    "This is for when TWO GROUPS are being compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8d9d28",
   "metadata": {},
   "source": [
    "Then $p$-value is found via:\n",
    "$$\n",
    "\\text{p-value} = P(F_{2,17} \\ge 6.1389)\\approx 0.00985.\n",
    "$$\n",
    "THIS USES numbers from the exercise 5.1, but $6.1389$ is from the $F$ formula above, and $F_{2,17}$ is from $F\\sim F_{p,n_X+n_Y-p-1}$ where the exercise had $10$ observations in each group and $p=2$ variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12be7c51",
   "metadata": {},
   "source": [
    "##### **Formula for testing that last p-q variables do not contribute to discrimination between population x and y (exam 2020 problem 4):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e51003f",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "\\frac{n_1 + n_2-p-1}{p-q} \\cdot \\frac{d^2-d_1^2}{(n_1+n_2)(n_1+n_2-2)/(n_1n_2)+d_1^2} \\sim F(p-q, n_X+n_Y-p-1)\n",
    "$$\n",
    "This is for when testing that the last $p-q$ VARIABLES do not contribute to discrimination between population $X$ and $Y$. Here, $d^2$ is the squared Mahanalobis distance for the full model and $d_1^2$ is the squared Mahanalobis distance for the reduced model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf414ef",
   "metadata": {},
   "source": [
    "##### **Rule of thumb for multicollinearity (from exam 2022 problem 4):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb20512",
   "metadata": {},
   "source": [
    "General rule of thumb for multicollinearity problem:\n",
    "\n",
    "$$TOL < 0.1$$\n",
    "\n",
    "$$VIF > 10$$\n",
    "\n",
    "Both of these indicates multicollinearity problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481dc62",
   "metadata": {},
   "source": [
    "Then a definition of the condition number (another multicollinearity diagnostic):\n",
    "$$\n",
    "\\text{Condition number} = \\sqrt{\\frac{\\lambda_{\\text{max}}}{\\lambda_{\\text{min}}}}\n",
    "$$\n",
    "Should be $< 15$, and above $30$ is serious concern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d85834",
   "metadata": {},
   "source": [
    "##### **Formula for usual test statistic for Wilk's Lambda (from exam 2014 problem 6 or 2011 problem 3):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968134a8",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "U(p, k-1, n-k)\n",
    "$$\n",
    "Where $p$ is number of response dimensions, $k-1$ is number of restrictions or $k$ is the number of groups, and $n-k$ is the degrees of freedom for error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098f7a7",
   "metadata": {},
   "source": [
    "##### **Test for additional information in LDA (Theorem 5.19) in exam 2024 problem 2:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e7e08",
   "metadata": {},
   "source": [
    "Formula:\n",
    "$$\n",
    "U(p,k-1,n-k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ff27a5",
   "metadata": {},
   "source": [
    "OR for multivariate regression:\n",
    "$$\n",
    "U(p, q, n  - r)\n",
    "$$\n",
    "SEE EXAM 2024 problem 5. Here, $p$ is number of response variables, $q$ is number of added predictors, $n$ is number of observations, and $r$ is number of predictors in each response variable."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
