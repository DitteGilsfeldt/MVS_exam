{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a6def4",
   "metadata": {},
   "source": [
    "# **MS R code cheat sheet**\n",
    "\n",
    "*(Based strictly on course R-lectures - everything you need for regression, PCA, LDA, MANOVA, factor analysis, diagnostics, selection ans more)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e9aef5",
   "metadata": {},
   "source": [
    "Load data:\n",
    "```R\n",
    "source(\"path/data_name.R\")\n",
    "```\n",
    "\n",
    "If data is csv, change sep if needed and `dec = \",\"` if needed for comma decimal:\n",
    "\n",
    "```R\n",
    "read.csv(\"exam_data/qsar_fish_toxicity3.csv\", header = TRUE, sep = \";\", dec = \",\")\n",
    "```\n",
    "\n",
    "If data is txt, change sep if needed:\n",
    "\n",
    "```R\n",
    "read.table(\"exam_data/data_name.txt\", header = TRUE, sep = \"\\t\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39726dff",
   "metadata": {},
   "source": [
    "## **Model basics & coefficients**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ac4aea",
   "metadata": {},
   "source": [
    "```R\n",
    "model <- lm(y ~ x1 + x2*x3 + I(x4^2), data=df)  # interaction, transform\n",
    "coef(model)                 # coefficients\n",
    "confint(model)              # 95% CI for betas\n",
    "summary(model)$coefficients # table with estimates, SE, t, p\n",
    "model.matrix(model)         # design matrix (useful in exams)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fd792",
   "metadata": {},
   "source": [
    "## **Predictions & intervals**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56949ec",
   "metadata": {},
   "source": [
    "```R\n",
    "new <- data.frame(x1=1:3, x2=c(0,1,1), x3=c(4,5,6))\n",
    "predict(model, new, type=\"response\")                       # fitted values\n",
    "predict(model, new, interval=\"confidence\", level=0.95)     # mean CI\n",
    "predict(model, new, interval=\"prediction\", level=0.95)     # prediction intervals\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2ae15",
   "metadata": {},
   "source": [
    "## **Good diagnostic checklist (one place)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d799b86",
   "metadata": {},
   "source": [
    "```R\n",
    "# Basic residual plots\n",
    "par(mfrow=c(2,2)); plot(model); par(mfrow=c(1,1))\n",
    "\n",
    "# Numerical diagnostics\n",
    "resid  <- residuals(model)\n",
    "rstd  <- rstudent(model)          # studentized\n",
    "lev   <- hatvalues(model)         # leverage\n",
    "cooks <- cooks.distance(model)\n",
    "\n",
    "# counts / flags\n",
    "sum(abs(rstd) > 2)                # how many |Rstudent|>2\n",
    "influential_idx <- which(abs(rstd)>2 & lev > 2*mean(lev))\n",
    "influential_idx\n",
    "\n",
    "# Influence table (car)\n",
    "library(car)\n",
    "influenceIndexPlot(model, id.n=5) # plots Cook's, hat, studentized\n",
    "avPlots(model)                    # added variable plots\n",
    "crPlots(model)                    # component + residual plots\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ce547c",
   "metadata": {},
   "source": [
    "### **Hot/cold diagnostics snippets (explicit values exams ask for)**\n",
    "\n",
    "```R\n",
    "rstd <- rstudent(model)\n",
    "sum(abs(rstd) > 2)                # count |Rstudent|>2\n",
    "lev <- hatvalues(model)\n",
    "sum(abs(rstd) > 2 & lev > 2*mean(lev))  # influential by course rule\n",
    "which(cooks.distance(model) > 4/length(residuals(model)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6ff16",
   "metadata": {},
   "source": [
    "## **Collinearity**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15697be",
   "metadata": {},
   "source": [
    "```R\n",
    "library(car)\n",
    "vif(model)                 # VIF; >10 bad in many contexts\n",
    "1/vif(model)               # tolerances\n",
    "# Condition index\n",
    "X <- model.matrix(model)\n",
    "e <- eigen(cor(X[,-1]))$values\n",
    "sqrt(max(e)/e)             # condition indices\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efacb3",
   "metadata": {},
   "source": [
    "## **Tests for assumptions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7eedee",
   "metadata": {},
   "source": [
    "```R\n",
    "library(lmtest)\n",
    "dwtest(model)               # Durbin-Watson (autocorrelation)\n",
    "bptest(model)               # Breusch-Pagan (heteroskedasticity)\n",
    "shapiro.test(resid)         # normality of residuals (small-sample)\n",
    "ncvTest(model)              # non-constant variance (car)\n",
    "# Multivariate normality (if needed):\n",
    "library(MVN); mvn(df[, c(\"x1\",\"x2\")], mvnTest=\"mardia\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771565b3",
   "metadata": {},
   "source": [
    "## **Robust standard errors & robust regression**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ce0c6",
   "metadata": {},
   "source": [
    "```R\n",
    "library(sandwich); library(lmtest)\n",
    "coeftest(model, vcov = vcovHC(model, type=\"HC3\"))  # robust SEs\n",
    "\n",
    "# Robust regression (less sensitive to outliers)\n",
    "library(MASS)\n",
    "rlm.model <- rlm(y ~ x1 + x2, data=df)\n",
    "summary(rlm.model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8668f5b",
   "metadata": {},
   "source": [
    "## **Influence and outlier diagnostics (numerical)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d6e8e",
   "metadata": {},
   "source": [
    "```R\n",
    "# Mahalanobis distance for multivariate outliers\n",
    "Xnum <- na.omit(df[, c(\"x1\",\"x2\",\"x3\")])\n",
    "md <- mahalanobis(Xnum, colMeans(Xnum), cov(Xnum))\n",
    "cutoff <- qchisq(0.975, df=ncol(Xnum))\n",
    "which(md > cutoff)         # potential multivariate outliers\n",
    "\n",
    "# Cook's influential observations\n",
    "which(cooks > 4/length(cooks))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae31186",
   "metadata": {},
   "source": [
    "## **Model comparison & selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c2c07c",
   "metadata": {},
   "source": [
    "```R\n",
    "# nested model F-test\n",
    "m1 <- lm(y ~ x1 + x2, data=df)\n",
    "m2 <- lm(y ~ x1 + x2 + x3, data=df)\n",
    "anova(m1, m2)               # partial F-test\n",
    "\n",
    "# AIC / BIC\n",
    "AIC(m1); BIC(m1)\n",
    "\n",
    "# stepwise (both) using AIC\n",
    "full <- lm(y ~ x1 + x2 + x3 + x4, data=df)\n",
    "step(full, direction=\"both\", trace=0)\n",
    "\n",
    "# stepAIC (MASS) uses AIC by default, can penalize differently\n",
    "library(MASS)\n",
    "stepAIC(full, trace=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be2371a",
   "metadata": {},
   "source": [
    "## **Exhaustive / best subsets**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f67be",
   "metadata": {},
   "source": [
    "```R\n",
    "library(leaps)\n",
    "leaps <- regsubsets(y ~ x1 + x2 + x3 + x4, data=df, nbest=5)\n",
    "summary(leaps)              # examine R2, adjR2, Cp\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff189f7d",
   "metadata": {},
   "source": [
    "## **Penalized regression (ridge/lasso) & CV**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e095d01b",
   "metadata": {},
   "source": [
    "```R\n",
    "library(glmnet)\n",
    "X <- model.matrix(y ~ x1 + x2 + x3, data=df)[,-1]\n",
    "yvec <- df$y\n",
    "cv.lasso <- cv.glmnet(X, yvec, alpha=1)  # lasso\n",
    "coef(cv.lasso, s=\"lambda.min\")\n",
    "cv.ridge  <- cv.glmnet(X, yvec, alpha=0) # ridge\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e648c4",
   "metadata": {},
   "source": [
    "## **Linear Regression (GLM)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244ade48",
   "metadata": {},
   "source": [
    "\n",
    "Model:\n",
    "$$\n",
    "y = \\alpha + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\varepsilon\n",
    "$$\n",
    "\n",
    "##### **R code**\n",
    "\n",
    "```r\n",
    "model <- lm(y ~ x1 + x2 + x3, data = df)\n",
    "summary(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8404fffb",
   "metadata": {},
   "source": [
    "### **Extract $R^2$, adjusted R²**\n",
    "\n",
    "```r\n",
    "summary(model)$r.squared\n",
    "summary(model)$adj.r.squared\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92da5c45",
   "metadata": {},
   "source": [
    "### **SSE find sum of squared residuals**\n",
    "\n",
    "```r\n",
    "SSE <- sum(residuals(model)^2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e98102",
   "metadata": {},
   "source": [
    "### **Residual diagnostics**\n",
    "\n",
    "```r\n",
    "plot(model)                # Residual plots\n",
    "rstudent(model)            # Studentized residuals\n",
    "hatvalues(model)           # Leverage (h_ii)\n",
    "cooks.distance(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01c8aa2",
   "metadata": {},
   "source": [
    "### **Count $|\\text{Rstudent}| > 2$**\n",
    "\n",
    "```r\n",
    "sum(abs(rstudent(model)) > 2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def97143",
   "metadata": {},
   "source": [
    "### **Influential obs (Rstudent $> 2$ & leverage $>$ threshold)**\n",
    "\n",
    "```r\n",
    "lev <- hatvalues(model)\n",
    "rst <- abs(rstudent(model))\n",
    "sum(rst > 2 & lev > 2*mean(lev))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637ef923",
   "metadata": {},
   "source": [
    "### **VIF + Tolerance**\n",
    "\n",
    "```r\n",
    "library(car)\n",
    "vif(model)           # VIF>10 indicates multicollinearity (then multicollinearity)\n",
    "1/vif(model)         # Tolerance has to be < 0.1 (then multicollinearity)\n",
    "                     # If VIF < 10 AND Tolerance > 0.1, then NO multicollinearity\n",
    "```         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8de3c2",
   "metadata": {},
   "source": [
    "### **Backwards elimination**\n",
    "\n",
    "```r\n",
    "drop1(model, test=\"F\")   # find variable to remove\n",
    "```\n",
    "\n",
    "We always remove the least significant variable (lowest $F$-value) and this equals to the highest $p$-value.Because in the linear model:\n",
    "$$\n",
    "F = \\frac{\\text{SSR removed}}{\\sigma^2}\n",
    "$$\n",
    "\n",
    "Small F $\\to$ removing the variable barely increases RSS which means that the variable is not important so we can remove it first. OR WE CAN look at the $t$-values where we just remove the one with lowest $t$-value, and to find $F$-value from $t$-value we can use that $F = t^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a038372",
   "metadata": {},
   "source": [
    "### **Forward selection (start with no predictors)**\n",
    "\n",
    "```r\n",
    "add1(lm(y ~ 1, data=df), scope = ~ x1+x2+x3, test=\"F\")\n",
    "```\n",
    "\n",
    "We pick the one with highest $F$-value (lowest $p$-value) to add first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3df80",
   "metadata": {},
   "source": [
    "## **Logistic Regression (binary)**\n",
    "\n",
    "Model\n",
    "\n",
    "$$\n",
    "\\text{logit}(p) = \\alpha + \\beta x\n",
    "$$\n",
    "\n",
    "### **R code**\n",
    "\n",
    "```r\n",
    "model <- glm(y ~ x, family=binomial(link=\"logit\"), data=df)\n",
    "summary(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3221f",
   "metadata": {},
   "source": [
    "```R\n",
    "logmod <- glm(ybin ~ x1 + x2, family=binomial, data=df)\n",
    "summary(logmod)\n",
    "# predicted probability & classification\n",
    "p <- predict(logmod, type=\"response\")\n",
    "pred_class <- ifelse(p > 0.5, 1, 0)\n",
    "table(pred_class, df$ybin)\n",
    "\n",
    "# AUC / ROC\n",
    "library(pROC)\n",
    "roc.obj <- roc(df$ybin, p)\n",
    "auc(roc.obj); plot.roc(roc.obj)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa0050",
   "metadata": {},
   "source": [
    "### **Prediction**\n",
    "\n",
    "```r\n",
    "predict(model, newdata=df, type=\"response\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04bbb6e",
   "metadata": {},
   "source": [
    "## **Linear Discriminant Analysis (LDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865962fe",
   "metadata": {},
   "source": [
    "### **Fit LDA**\n",
    "\n",
    "```r\n",
    "library(MASS)\n",
    "lda.model <- lda(group ~ x1 + x2 + x3, data=df)\n",
    "lda.model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202ab01",
   "metadata": {},
   "source": [
    "### **Resubstitution errors**\n",
    "\n",
    "```r\n",
    "pred <- predict(lda.model)$class\n",
    "sum(pred != df$group)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9661362f",
   "metadata": {},
   "source": [
    "### **Posterior probabilities**\n",
    "\n",
    "```r\n",
    "predict(lda.model)$posterior\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd16d32",
   "metadata": {},
   "source": [
    "### **LDA - CV, posterior probs, confusion**\n",
    "\n",
    "```R\n",
    "library(MASS)\n",
    "lda.model <- lda(group ~ x1 + x2 + x3, data=df)\n",
    "pred <- predict(lda.model)                # $class, $posterior, $x\n",
    "table(pred$class, df$group)              # resubstitution confusion\n",
    "lda.cv <- lda(group ~ x1 + x2 + x3, data=df, CV=TRUE)\n",
    "table(lda.cv$class, df$group)            # cross-validated table\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc14df",
   "metadata": {},
   "source": [
    "## **LDA / QDA / classification helpers**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7eef9b",
   "metadata": {},
   "source": [
    "```R\n",
    "library(MASS)\n",
    "lda.model <- lda(group ~ x1 + x2 + x3, data=df)\n",
    "pred <- predict(lda.model)         # $class, $posterior, $x (scores)\n",
    "table(pred$class, df$group)        # resubstitution confusion matrix\n",
    "\n",
    "# cross-validated LDA\n",
    "lda.cv <- lda(group ~ x1 + x2, data=df, CV=TRUE)\n",
    "table(lda.cv$class, df$group)      # CV table\n",
    "\n",
    "# confusion & performance (caret)\n",
    "library(caret)\n",
    "confusionMatrix(as.factor(pred$class), df$group)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf6bd2",
   "metadata": {},
   "source": [
    "## **MANOVA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837de728",
   "metadata": {},
   "source": [
    "### **Model**\n",
    "\n",
    "$$\n",
    "Y = \\mu + \\text{Group}\n",
    "$$\n",
    "\n",
    "```r\n",
    "fit <- manova(cbind(y1, y2, y3) ~ group, data=df)\n",
    "summary(fit, test=\"Wilks\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f01efe3",
   "metadata": {},
   "source": [
    "### **Test of individual variables (Type III)**\n",
    "\n",
    "```r\n",
    "library(car)\n",
    "Anova(fit)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c0e3a",
   "metadata": {},
   "source": [
    "### **MANOVA tests (Wilks / Pillai) and Type-III for individual responses**\n",
    "\n",
    "```R\n",
    "fit <- manova(cbind(y1,y2,y3) ~ group, data=df)\n",
    "summary(fit, test=\"Wilks\")    # Wilks' lambda\n",
    "summary(fit, test=\"Pillai\")   # Pillai's trace\n",
    "library(car)\n",
    "Anova(fit, type=\"III\")        # Type III tests for each response (if needed)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5fa25b",
   "metadata": {},
   "source": [
    "### **ANOVA**\n",
    "\n",
    "```r\n",
    "# nested F-test\n",
    "anova(m_small, m_big)\n",
    "\n",
    "# Breusch-Pagan, Durbin-Watson\n",
    "library(lmtest)\n",
    "bptest(model); dwtest(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daaab87",
   "metadata": {},
   "source": [
    "## **Hotelling’s $T^2$, multivariate tests**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9cae81",
   "metadata": {},
   "source": [
    "```R\n",
    "# MANOVA (Wilks, Pillai etc.)\n",
    "fit <- manova(cbind(y1,y2,y3) ~ group, data=df)\n",
    "summary(fit, test=\"Wilks\")\n",
    "summary(fit, test=\"Pillai\")\n",
    "\n",
    "# Type III tests for MANOVA\n",
    "library(car)\n",
    "Anova(fit, type=\"III\")\n",
    "\n",
    "# Hotelling T2 (two-sample)\n",
    "library(Hotelling)\n",
    "hotelling.test(X[group==1, ], X[group==2, ])  # two-sample T2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466c11bf",
   "metadata": {},
   "source": [
    "### **Hotelling's $T^2$ for two-sample multivariate test**\n",
    "\n",
    "```R\n",
    "hot <- hotelling.test(X[group==1, ], X[group==2, ])\n",
    "hot\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df60fdf2",
   "metadata": {},
   "source": [
    "## **PCA (Principal Component Analysis)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317d0b6",
   "metadata": {},
   "source": [
    "### **Scale $=$ TRUE $\\to$ correlation matrix**\n",
    "\n",
    "(*used when variables have different units, like in lectures*)\n",
    "\n",
    "```r\n",
    "p <- prcomp(df, scale=TRUE)\n",
    "summary(p)      # variance explained\n",
    "p$rotation      # loadings\n",
    "p$x             # scores\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98504b4",
   "metadata": {},
   "source": [
    "```R\n",
    "# prcomp uses scaling = TRUE -> correlation matrix\n",
    "p <- prcomp(df[, c(\"x1\",\"x2\",\"x3\")], scale.=TRUE)\n",
    "summary(p)             # variances and cumulative proportions\n",
    "p$rotation             # loadings\n",
    "p$x                    # scores\n",
    "\n",
    "# plots\n",
    "screeplot(p, type=\"lines\")\n",
    "biplot(p, scale=0)     # built-in simple biplot\n",
    "\n",
    "# nicer plotting (factoextra)\n",
    "library(factoextra)\n",
    "fviz_eig(p)            # explained variance plot\n",
    "fviz_pca_biplot(p, repel=TRUE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8642c9d",
   "metadata": {},
   "source": [
    "### **Extract eigenvalues / scree for PCA & deciding #components**\n",
    "\n",
    "```R\n",
    "p <- prcomp(df[,vars], scale.=TRUE)\n",
    "eig <- p$sdev^2\n",
    "cbind(eig, eig/sum(eig), cumsum(eig/sum(eig)))  # eigen, prop, cum.prop\n",
    "plot(eig, type=\"b\")                              # scree\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaa1dfe",
   "metadata": {},
   "source": [
    "## **Factor Analysis (Principal Factor, VARIMAX)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a345068",
   "metadata": {},
   "source": [
    "### **Extraction**\n",
    "\n",
    "```r\n",
    "fa <- factanal(df, factors=3, rotation=\"varimax\")\n",
    "fa\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0502ac82",
   "metadata": {},
   "source": [
    "### **Extraction (Principal Factor, Varimax)**\n",
    "\n",
    "```R\n",
    "fa <- factanal(df, factors = 3, rotation = \"varimax\")\n",
    "fa\n",
    "fa$ <- loadings(fa)          # loadings\n",
    "fa$scores                    # scores if scored=TRUE was set\n",
    "```\n",
    "\n",
    "### **If you want scores (optional but allowed syntax):**\n",
    "\n",
    "```R\n",
    "fa <- factanal(df, factors = 3, rotation = \"varimax\", scores=\"regression\")\n",
    "fa$scores\n",
    "```\n",
    "\n",
    "### **Scree plot (if taught via eigenvalues PCA-style)**\n",
    "\n",
    "```R\n",
    "ev <- eigen(cor(df))$values\n",
    "plot(ev, type=\"b\")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f1c9a",
   "metadata": {},
   "source": [
    "### **Canonical correlation**\n",
    "\n",
    "```R\n",
    "cc <- cancor(Xset, Yset)   # Xset and Yset are two matrices/data.frames\n",
    "cc$cor                    # canonical correlations\n",
    "summary(cc)               # inspect weights\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeb38c5",
   "metadata": {},
   "source": [
    "### **Print loadings and request scores (exam style)**\n",
    "\n",
    "```R\n",
    "fa <- factanal(df[,vars], factors=3, rotation=\"varimax\", scores=\"regression\")\n",
    "print(fa, digits=3, cutoff=0.30)   # prints loadings with cutoff\n",
    "loadings(fa)                       # explicit loadings object\n",
    "fa$scores                          # factor scores (if requested)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62b5eb8",
   "metadata": {},
   "source": [
    "## **Multivariate Normal Density / KDE (from lectures)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d641b81",
   "metadata": {},
   "source": [
    "\n",
    "### **2D kernel density plot**\n",
    "\n",
    "```r\n",
    "library(MASS)\n",
    "d <- kde2d(x, y)\n",
    "persp(d)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d219e",
   "metadata": {},
   "source": [
    "```R\n",
    "# Mahalanobis / density\n",
    "mv_mean <- colMeans(Xnum); mv_cov <- cov(Xnum)\n",
    "d2 <- mahalanobis(Xnum, mv_mean, mv_cov)\n",
    "# kernel density 2D\n",
    "library(MASS)\n",
    "d <- kde2d(Xnum[,1], Xnum[,2], n=50)\n",
    "persp(d)   # or image(d); contour(d, add=TRUE)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa5ac2e",
   "metadata": {},
   "source": [
    "## **Useful helper functions from Lectures**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08880b2",
   "metadata": {},
   "source": [
    "### **Logit + Logistic**\n",
    "\n",
    "```r\n",
    "logit <- function(p) log(p/(1-p))\n",
    "logistic <- function(y) exp(y)/(1+exp(y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3b382",
   "metadata": {},
   "source": [
    "```R\n",
    "# SSR and SSE\n",
    "SSE <- sum(residuals(model)^2)\n",
    "SSR <- sum((fitted(model) - mean(df$y))^2)\n",
    "SST <- sum((df$y - mean(df$y))^2)\n",
    "# R2 check\n",
    "summary(model)$r.squared\n",
    "summary(model)$adj.r.squared\n",
    "\n",
    "# number of estimated params\n",
    "length(coef(model))\n",
    "\n",
    "# Extract p-values\n",
    "coef(summary(model))[,4]\n",
    "\n",
    "# t -> F: F = t^2 for testing one parameter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f57232",
   "metadata": {},
   "source": [
    "## **Common exam patterns**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203d0ce",
   "metadata": {},
   "source": [
    "### \"Compute R of the model\"\n",
    "\n",
    "> **Use Multiple $R^2$**\n",
    "\n",
    "### \"How many obs have $|\\text{Rstudent}| > 2$\"\n",
    "\n",
    "> `sum(abs(rstudent(model)) > 2)`\n",
    "\n",
    "### \"Influential $=$ Rstudent $>2$ & leverage $>$ threshold\"\n",
    "\n",
    "> `sum(rst>2 & lev>threshold)`\n",
    "\n",
    "### \"Forward backward selection\"\n",
    "\n",
    ">  `add1()` and `drop1()`\n",
    "\n",
    "### \"Multicollinearity\"\n",
    "\n",
    "> Look at `vif()`\n",
    "\n",
    "### \"Test nested model\" ($F$-test)\n",
    "\n",
    "> Look at: \n",
    "```r\n",
    "anova(model_small, model_big)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "name": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
