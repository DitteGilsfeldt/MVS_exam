{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dd9734",
   "metadata": {},
   "source": [
    "# Exam 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e67eed",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-32-18.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391d19f5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     name           mfr    type      calories      protein           fat       \n",
       " Length:76          G:22   C:74   Min.   : 50   Min.   :1.000   Min.   :0.000  \n",
       " Class :character   K:23   H: 2   1st Qu.:100   1st Qu.:2.000   1st Qu.:0.000  \n",
       " Mode  :character   N: 6          Median :110   Median :2.500   Median :1.000  \n",
       "                    P: 9          Mean   :107   Mean   :2.526   Mean   :1.013  \n",
       "                    Q: 8          3rd Qu.:110   3rd Qu.:3.000   3rd Qu.:2.000  \n",
       "                    R: 8          Max.   :160   Max.   :6.000   Max.   :5.000  \n",
       "     sodium          fiber           carbo           sugars      \n",
       " Min.   :  0.0   Min.   : 0.00   Min.   :-1.00   Min.   :-1.000  \n",
       " 1st Qu.:133.8   1st Qu.: 1.00   1st Qu.:12.00   1st Qu.: 3.000  \n",
       " Median :180.0   Median : 2.00   Median :14.00   Median : 7.000  \n",
       " Mean   :161.8   Mean   : 2.18   Mean   :14.58   Mean   : 6.974  \n",
       " 3rd Qu.:212.5   3rd Qu.: 3.00   3rd Qu.:17.00   3rd Qu.:11.000  \n",
       " Max.   :320.0   Max.   :14.00   Max.   :23.00   Max.   :15.000  \n",
       "     potass          vitamins          shelf           weight    \n",
       " Min.   : -1.00   Min.   :  0.00   Min.   :1.000   Min.   :0.50  \n",
       " 1st Qu.: 40.00   1st Qu.: 25.00   1st Qu.:1.000   1st Qu.:1.00  \n",
       " Median : 90.00   Median : 25.00   Median :2.000   Median :1.00  \n",
       " Mean   : 96.09   Mean   : 28.29   Mean   :2.211   Mean   :1.03  \n",
       " 3rd Qu.:120.00   3rd Qu.: 25.00   3rd Qu.:3.000   3rd Qu.:1.00  \n",
       " Max.   :330.00   Max.   :100.00   Max.   :3.000   Max.   :1.50  \n",
       "      cups            rating     \n",
       " Min.   :0.2500   Min.   :18.04  \n",
       " 1st Qu.:0.6700   1st Qu.:32.93  \n",
       " Median :0.7500   Median :40.25  \n",
       " Mean   :0.8187   Mean   :42.51  \n",
       " 3rd Qu.:1.0000   3rd Qu.:50.78  \n",
       " Max.   :1.5000   Max.   :93.70  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "breakfast <- data.frame(\"name\"= c(\"100Bran\",\"100NaturalBran\",\"AllBran\",\"AllBranFiber\",\"AlmondDelight\",\"AppleCinnamonCheerios\",\"AppleJacks\",\"Basic4\",\"BranChex\",\"BranFlakes\",\"CapCrunch\",\"Cheerios\",\"CinnamonToastCrunch\",\"Clusters\",\"CocoaPuffs\",\"CornChex\",\"CornFlakes\",\"CornPops\",\"CountChocula\",\"CracklinOatBran\",\"CreamWheat\",\"Crispix\",\"CrispyWheatRaisins\",\"DoubleChex\",\"FrootLoops\",\"FrostedFlakes\",\"FrostedMiniWheats\",\"FruitFibreDates\",\"FruitfulBran\",\"FruityPebbles\",\"GoldenCrisp\",\"GoldenGrahams\",\"GrapeNutsFlakes\",\"GrapeNuts\",\"GreatGrainsPecan\",\"HoneyGraham\",\"HoneyNutCheerios\",\"Honeycomb\",\"JustRightCrunchyNuggets\",\"JustRightFruitNut\",\"Kix\",\"Life\",\"LuckyCharms\",\"MuesliRaisinsDatesAlmonds\",\"MuesliRaisinsPeachesPecans\",\"MueslixCrispyBlend\",\"MultiGrainCheerios\",\"NutHoneyCrunch\",\"NutriGrainAlmondRaisin\",\"NutrigrainWheat\",\"OatmealRaisinCrisp\",\"PostNatRaisinBran\",\"Product19\",\"PuffedRice\",\"PuffedWheat\",\"QuakerOatSquares\",\"QuakerOatmeal\",\"RaisinBran\",\"RaisinNutBran\",\"RaisinSquares\",\"RiceChex\",\"RiceKrispies\",\"ShreddedWheat\",\"ShreddedWheatBran\",\"ShreddedWheatspoonsize\",\"Smacks\",\"SpecialK\",\"StrawberryFruitWheats\",\"TotalCornFlakes\",\"TotalRaisinBran\",\"TotalWholeGrain\",\"Triples\",\"Trix\",\"WheatChex\",\"Wheaties\",\"WheatiesHoneyGold\"),\n",
    "                        \"mfr\" = factor(c(3,5,2,2,6,1,2,1,6,4,5,1,1,1,1,6,2,2,1,2,3,2,1,6,2,2,2,4,2,4,4,1,4,4,4,5,1,4,2,2,1,5,1,6,6,2,1,2,2,2,1,4,2,5,5,5,5,2,1,2,6,2,3,3,3,2,2,3,1,1,1,1,1,6,1,1), levels= c(1,2,3,4,5,6), labels = c(\"G\", \"K\", \"N\", \"P\", \"Q\", \"R\")),\n",
    "                        \"type\" = factor(c(\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"H\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"H\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\")),\n",
    "                        \"calories\" = c(70,120,70,50,110,110,110,130,90,90,120,110,120,110,110,110,100,110,110,110,100,110,100,100,110,110,100,120,120,110,100,110,100,110,120,120,110,110,110,140,110,100,110,150,150,160,100,120,140,90,130,120,100,50,50,100,100,120,100,90,110,110,80,90,90,110,110,90,110,140,100,110,110,100,100,110),\n",
    "                        \"protein\" = c(4,3,4,4,2,2,2,3,2,3,1,6,1,3,1,2,2,1,1,3,3,2,2,2,2,1,3,3,3,1,2,1,3,3,3,1,3,1,2,3,2,4,2,4,4,3,2,2,3,3,3,3,3,1,2,4,5,3,3,2,1,2,2,3,3,2,6,2,2,3,3,2,1,3,3,2),\n",
    "                        \"fat\" = c(1,5,1,0,2,2,0,2,1,0,2,2,3,2,1,0,0,0,1,3,0,0,1,0,1,0,0,2,0,1,0,1,1,0,3,2,1,0,1,1,1,2,1,3,3,2,1,1,2,0,2,1,0,0,0,1,2,1,2,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1),\n",
    "                        \"sodium\" = c(130,15,260,140,200,180,125,210,200,210,220,290,210,140,180,280,290,90,180,140,80,220,140,190,125,200,0,160,240,135,45,280,140,170,75,220,250,180,170,170,260,150,180,95,150,150,220,190,220,170,170,200,320,0,0,135,0,210,140,0,240,290,0,0,0,70,230,15,200,190,200,250,140,230,200,200),\n",
    "                        \"fiber\" = c(10,2,9,14,1,1.5,1,2,4,5,0,2,0,2,0,0,1,1,0,4,1,1,2,1,1,1,3,5,5,0,0,0,3,3,3,1,1.5,0,1,2,0,2,0,3,3,3,2,0,3,3,1.5,6,1,0,1,2,2.7,5,2.5,2,0,0,3,4,3,1,1,3,0,4,3,0,0,3,3,1),\n",
    "                        \"carbo\" = c(5,8,7,8,14,10.5,11,18,15,13,12,17,13,13,12,22,21,13,12,10,21,21,11,18,11,14,14,12,14,13,11,15,15,17,13,12,11.5,14,17,20,21,12,12,16,16,17,15,15,21,18,13.5,11,20,13,10,14,-1,14,10.5,15,23,22,16,19,20,9,16,15,21,15,16,21,13,17,17,16),\n",
    "                        \"sugars\" = c(6,8,5,0,8,10,14,8,6,5,12,1,9,7,13,3,2,12,13,7,0,3,10,5,13,11,7,10,12,12,15,9,5,3,4,11,10,11,6,9,3,6,12,11,11,13,6,9,7,2,10,14,3,0,0,6,-1,12,8,6,2,3,0,0,0,15,3,5,3,14,3,3,12,3,3,8),\n",
    "                        \"potass\" = c(280,135,320,330,-1,70,30,100,125,190,35,105,45,105,55,25,35,20,65,160,-1,30,120,80,30,25,100,200,190,25,40,45,85,90,100,45,90,35,60,95,40,95,55,170,170,160,90,40,130,90,120,260,45,15,50,110,110,240,140,110,30,35,95,140,120,40,55,90,35,230,110,60,25,115,110,60),\n",
    "                        \"vitamins\" = c(25,0,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,0,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,100,100,25,25,25,25,25,25,25,25,25,25,25,25,100,0,0,25,0,25,25,25,25,25,0,0,0,25,25,25,100,100,100,25,25,25,25,25),\n",
    "                        \"shelf\" = c(3,3,3,3,3,1,2,3,1,3,2,1,2,3,2,1,1,2,2,3,2,3,3,3,2,1,2,3,3,2,1,2,3,3,3,2,1,1,3,3,2,2,2,3,3,3,1,2,3,3,3,3,3,3,3,3,1,2,3,3,1,1,1,1,1,2,1,2,3,3,3,3,2,1,1,1),\n",
    "                        \"weight\" = c(1,1,1,1,1,1,1,1.33,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1.25,1.33,1,1,1,1,1,1,1,1,1,1,1.3,1,1,1,1,1,1.5,1,1,1.33,1,1.25,1.33,1,0.5,0.5,1,1,1.33,1,1,1,1,0.83,1,1,1,1,1,1,1.5,1,1,1,1,1,1),\n",
    "                        \"cups\" = c(0.33,1,0.33,0.5,0.75,0.75,1,0.75,0.67,0.67,0.75,1.25,0.75,0.5,1,1,1,1,1,0.5,1,1,0.75,0.75,1,0.75,0.8,0.67,0.67,0.75,0.88,0.75,0.88,0.25,0.33,1,0.75,1.33,1,0.75,1.5,0.67,1,1,1,0.67,1,0.67,0.67,1,0.5,0.67,1,1,1,0.5,0.67,0.75,0.5,0.5,1.13,1,1,0.67,0.67,0.75,1,1,1,1,1,0.75,1,0.67,1,0.75),\n",
    "                        \"rating\" = c(68.402973,33.983679,59.425505,93.704912,34.384843,29.509541,33.174094,37.038562,49.120253,53.313813,18.042851,50.764999,19.823573,40.400208,22.736446,41.445019,45.863324,35.782791,22.396513,40.448772,64.533816,46.895644,36.176196,44.330856,32.207582,31.435973,58.345141,40.917047,41.015492,28.025765,35.252444,23.804043,52.076897,53.371007,45.811716,21.871292,31.072217,28.742414,36.523683,36.471512,39.241114,45.328074,26.734515,37.136863,34.139765,30.313351,40.105965,29.924285,40.69232,59.642837,30.450843,37.840594,41.50354,60.756112,63.005645,49.511874,50.828392,39.259197,39.7034,55.333142,41.998933,40.560159,68.235885,74.472949,72.801787,31.230054,53.131324,59.363993,38.839746,28.592785,46.658844,39.106174,27.753301,49.787445,51.592193,36.187559))\n",
    "\n",
    "summary(breakfast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533f33cf",
   "metadata": {},
   "source": [
    "### Question 1.1 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-32-39.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5839188e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "TRUE"
      ],
      "text/latex": [
       "TRUE"
      ],
      "text/markdown": [
       "TRUE"
      ],
      "text/plain": [
       "[1] TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "          Df  Wilks approx F num Df den Df   Pr(>F)    \n",
       "mfr        5 0.1661   3.0774     45 280.44 7.46e-09 ***\n",
       "Residuals 70                                           \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure mfr is a factor (it already is in your data)\n",
    "is.factor(breakfast$mfr)\n",
    "\n",
    "# MANOVA: all nine responses vs. mfr\n",
    "fit <- manova(cbind(calories, protein, fat, sodium, fiber, carbo, sugars, potass, rating) ~ mfr,\n",
    "              data = breakfast)\n",
    "\n",
    "# Wilks' Lambda table\n",
    "summary(fit, test = \"Wilks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20cf7d1d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.166096140868286"
      ],
      "text/latex": [
       "0.166096140868286"
      ],
      "text/markdown": [
       "0.166096140868286"
      ],
      "text/plain": [
       "[1] 0.1660961"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wilks <- summary(fit, test = \"Wilks\")$stats[1, \"Wilks\"]\n",
    "wilks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e99254",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option 2 - $0.1661$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992a046",
   "metadata": {},
   "source": [
    "### Question 1.2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-43-21.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777f4f6d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: carData\n",
      "\n",
      "Warning message:\n",
      "“package ‘carData’ was built under R version 4.5.1”\n"
     ]
    }
   ],
   "source": [
    "library(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8673530",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable: calories \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: calories\n",
      "            Sum Sq Df  F value  Pr(>F)    \n",
      "(Intercept) 272841  1 791.0993 < 2e-16 ***\n",
      "mfr           4662  5   2.7033 0.02724 *  \n",
      "Residuals    24142 70                     \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: protein \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: protein\n",
      "             Sum Sq Df F value    Pr(>F)    \n",
      "(Intercept) 118.227  1 95.2122 1.097e-14 ***\n",
      "mfr           2.027  5  0.3264    0.8954    \n",
      "Residuals    86.921 70                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: fat \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: fat\n",
      "            Sum Sq Df F value   Pr(>F)    \n",
      "(Intercept) 40.909  1 46.7217 2.49e-09 ***\n",
      "mfr         15.695  5  3.5851 0.006057 ** \n",
      "Residuals   61.291 70                     \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: sodium \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: sodium\n",
      "            Sum Sq Df  F value    Pr(>F)    \n",
      "(Intercept) 884005  1 188.8653 < 2.2e-16 ***\n",
      "mfr         180643  5   7.7188 7.925e-06 ***\n",
      "Residuals   327643 70                       \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: fiber \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: fiber\n",
      "            Sum Sq Df F value  Pr(>F)  \n",
      "(Intercept)  35.64  1  6.7020 0.01170 *\n",
      "mfr          54.81  5  2.0617 0.08054 .\n",
      "Residuals   372.21 70                  \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: carbo \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: carbo\n",
      "            Sum Sq Df  F value  Pr(>F)    \n",
      "(Intercept) 4771.6  1 300.5342 < 2e-16 ***\n",
      "mfr          278.1  5   3.5034 0.00696 ** \n",
      "Residuals   1111.4 70                     \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: sugars \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: sugars\n",
      "             Sum Sq Df F value    Pr(>F)    \n",
      "(Intercept) 1392.05  1 78.6231 4.638e-13 ***\n",
      "mfr          246.58  5  2.7853   0.02369 *  \n",
      "Residuals   1239.37 70                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: potass \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: potass\n",
      "            Sum Sq Df F value    Pr(>F)    \n",
      "(Intercept) 159801  1 30.0793 6.197e-07 ***\n",
      "mfr          14330  5  0.5395    0.7457    \n",
      "Residuals   371886 70                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
      "\n",
      "Variable: rating \n",
      "Anova Table (Type III tests)\n",
      "\n",
      "Response: rating\n",
      "             Sum Sq Df F value    Pr(>F)    \n",
      "(Intercept) 26164.0  1 193.344 < 2.2e-16 ***\n",
      "mfr          5373.7  5   7.942 5.683e-06 ***\n",
      "Residuals    9472.7 70                      \n",
      "---\n",
      "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
     ]
    }
   ],
   "source": [
    "# List of numeric dependent variables\n",
    "vars <- c(\"calories\", \"protein\", \"fat\", \"sodium\", \"fiber\",\n",
    "          \"carbo\", \"sugars\", \"potass\", \"rating\")\n",
    "\n",
    "# Calculate Type III SS for each variable\n",
    "for (v in vars) {\n",
    "  model <- lm(as.formula(paste(v, \"~ mfr\")), data = breakfast)\n",
    "  cat(\"\\nVariable:\", v, \"\\n\")\n",
    "  print(Anova(model, type = 3))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d4f9cc",
   "metadata": {},
   "source": [
    "Look at the “Sum Sq (mfr)” column\n",
    "\n",
    "Whichever variable shows the largest Type III SS for mfr has the biggest difference between manufacturers.\n",
    "\n",
    "When this is run on your dataset, you’ll see the largest Type III SS appears for sodium — the sodium content varies most strongly between cereal manufacturers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14a0e6e",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option D - Sodium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b52fa3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sodium       potass       rating     calories        carbo       sugars \n",
      "1.806426e+05 1.432994e+04 5.373697e+03 4.661765e+03 2.781234e+02 2.465768e+02 \n",
      "       fiber          fat      protein \n",
      "5.481267e+01 1.569545e+01 2.026694e+00 \n",
      "\n",
      "Largest Type III SS: sodium = 180642.6 \n"
     ]
    }
   ],
   "source": [
    "# Make Type III work cleanly\n",
    "options(contrasts = c(\"contr.sum\", \"contr.poly\"))\n",
    "library(car)\n",
    "\n",
    "vars <- c(\"calories\",\"protein\",\"fat\",\"sodium\",\"fiber\",\"carbo\",\"sugars\",\"potass\",\"rating\")\n",
    "\n",
    "# helper: return Type III SS for the mfr effect for one response\n",
    "type3_ss_mfr <- function(y) {\n",
    "  fit <- lm(reformulate(\"mfr\", response = y), data = breakfast)\n",
    "  a <- Anova(fit, type = 3)\n",
    "  # pick the non-intercept row robustly\n",
    "  mfr_row <- setdiff(rownames(a), \"(Intercept)\")[1]\n",
    "  as.numeric(a[mfr_row, \"Sum Sq\"])\n",
    "}\n",
    "\n",
    "# compute and sort\n",
    "ss_vec <- setNames(sapply(vars, type3_ss_mfr), vars)\n",
    "ss_sorted <- sort(ss_vec, decreasing = TRUE)\n",
    "\n",
    "print(ss_sorted)\n",
    "cat(\"\\nLargest Type III SS:\", names(ss_sorted)[1], \"=\", ss_sorted[1], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5825b40",
   "metadata": {},
   "source": [
    "#### Solution code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613a7c2",
   "metadata": {},
   "source": [
    "### Question 1.3\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-49-12.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f178f60b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U(9,5,70)\n"
     ]
    }
   ],
   "source": [
    "# 1) U-distribution parameters for Wilks' Lambda in one-way MANOVA\n",
    "p  <- 9                                # number of responses\n",
    "g  <- nlevels(breakfast$mfr)           # number of groups (manufacturers)\n",
    "n  <- nrow(breakfast)                  # total sample size\n",
    "\n",
    "U_params <- c(p, g - 1, n - g)\n",
    "cat(sprintf(\"U(%d,%d,%d)\\n\", U_params[1], U_params[2], U_params[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "158db093",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Df  Wilks approx F num Df den Df   Pr(>F)    \n",
       "mfr        5 0.1661   3.0774     45 280.44 7.46e-09 ***\n",
       "Residuals 70                                           \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2) Verify by fitting MANOVA and seeing the F-approx with its dfs\n",
    "fit <- manova(cbind(calories, protein, fat, sodium, fiber, carbo, sugars, potass, rating) ~ mfr,\n",
    "              data = breakfast)\n",
    "summary(fit, test = \"Wilks\")\n",
    "# This prints Wilks' Λ with its approximate F and numerator/denominator dfs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359cea23",
   "metadata": {},
   "source": [
    "**Model context**\n",
    "\n",
    "We tested whether the mean vectors differ between the 6 manufacturers (`mfr`) over $9$ response variables.\n",
    "That’s a **one-way MANOVA** with:\n",
    "\n",
    "* $g = 6$ groups (manufacturers)\n",
    "* $p = 9$ dependent variables\n",
    "* $n = 77$ total cereals (so residual $df \\approx 71$, but check below)\n",
    "\n",
    "**Degrees of freedom for Wilks’ Lambda test**\n",
    "\n",
    "For the MANOVA $Y = \\mu + mfr + \\epsilon$,\n",
    "the **approximate F transformation** of Wilks’ Lambda uses:\n",
    "\n",
    "$$\n",
    "U(p, g-1, n-g)\n",
    "$$\n",
    "notation or equivalent $F$-approximation $F(\\nu_1, \\nu_2)$.\n",
    "\n",
    "For a **one-way MANOVA** with $p = 9$ and $g-1 = 5$ manufacturer df:\n",
    "\n",
    "$$\n",
    "U(9, 5, 70)\n",
    "$$\n",
    "\n",
    "is the correct distribution for the test statistic under $H_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee91242",
   "metadata": {},
   "source": [
    "#### Solution code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "493e5f44",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of manufacturers: 6 \n",
      "Number of observations: 76 \n",
      "Number of variables: 9 \n"
     ]
    }
   ],
   "source": [
    "Q13_variables <- c(\"calories\", \"protein\", \"fat\", \"sodium\", \"fiber\", \"carbo\", \"sugars\", \"potass\",\"rating\")\n",
    "Q13_num_variables <- length(Q13_variables)\n",
    "cat(\"Number of manufacturers:\", length(unique(breakfast$mfr)),\"\\n\")\n",
    "cat(\"Number of observations:\", nrow(breakfast), \"\\n\")\n",
    "cat(\"Number of variables:\", Q13_num_variables, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968619c",
   "metadata": {},
   "source": [
    "### Question 1.4 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-10-59-41.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d0603c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n = 3 Ucrit = 0.0025 \n",
      "n = 4 Ucrit = 0.05 \n",
      "n = 5 Ucrit = 0.1357 \n",
      "n = 6 Ucrit = 0.2236 \n",
      "=> Significant at 5% level for n = 6 \n"
     ]
    }
   ],
   "source": [
    "alpha <- 0.05\n",
    "u_obs <- 0.2\n",
    "s <- 1\n",
    "r <- 2\n",
    "\n",
    "# test successive n values until Ucrit > u_obs\n",
    "for (n in 3:20) {\n",
    "  # transform to approximate F statistic\n",
    "  f_crit <- qf(1 - alpha, r, n - 2)\n",
    "  u_crit <- 1 / (1 + (r / (n - 2)) * f_crit)  # critical U\n",
    "  cat(\"n =\", n, \"Ucrit =\", round(u_crit, 4), \"\\n\")\n",
    "  if (u_obs <= u_crit) {\n",
    "    cat(\"=> Significant at 5% level for n =\", n, \"\\n\")\n",
    "    break\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738e3d70",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n     Ucrit significant\n",
      "1   3 0.0025000       FALSE\n",
      "2   4 0.0500000       FALSE\n",
      "3   5 0.1357209       FALSE\n",
      "4   6 0.2236068        TRUE\n",
      "5   7 0.3017088        TRUE\n",
      "6   8 0.3684031        TRUE\n",
      "7   9 0.4248906        TRUE\n",
      "8  10 0.4728708        TRUE\n",
      "9  11 0.5139043        TRUE\n",
      "10 12 0.5492803        TRUE\n",
      "11 13 0.5800282        TRUE\n",
      "12 14 0.6069622        TRUE\n",
      "13 15 0.6307272        TRUE\n",
      "14 16 0.6518363        TRUE\n",
      "15 17 0.6707016        TRUE\n",
      "16 18 0.6876560        TRUE\n",
      "17 19 0.7029714        TRUE\n",
      "18 20 0.7168712        TRUE\n",
      "Smallest n with significance: 6 \n"
     ]
    }
   ],
   "source": [
    "alpha <- 0.05\n",
    "u_obs <- 0.2\n",
    "s <- 1; r <- 2\n",
    "\n",
    "u_crit <- function(n) {\n",
    "  df2 <- n - 2\n",
    "  fcrit <- qf(1 - alpha, r, df2)\n",
    "  1 / (1 + (r / df2) * fcrit)\n",
    "}\n",
    "\n",
    "# show table and minimum n\n",
    "ns <- 3:20\n",
    "tab <- data.frame(n = ns,\n",
    "                  Ucrit = sapply(ns, u_crit),\n",
    "                  significant = u_obs <= sapply(ns, u_crit))\n",
    "print(tab)\n",
    "\n",
    "min_n <- min(tab$n[tab$significant])\n",
    "cat(\"Smallest n with significance:\", min_n, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e0c534",
   "metadata": {},
   "source": [
    "We are testing the significance of a statistic that follows\n",
    "$$\n",
    "U(s, r, n-k) = U(1, 2, n-2)\n",
    "$$\n",
    "with an observed value of $u = 0.2$, at the 5% significance level.\n",
    "\n",
    "In this type of MANOVA-based test, **smaller values of $U$** indicate stronger evidence against the null hypothesis.\n",
    "Therefore, we reject $H_0$ when the **observed U** is **less than or equal to the critical U-value**:\n",
    "$$\n",
    "u_{\\text{obs}} \\le U_{\\text{crit}}\n",
    "$$\n",
    "\n",
    "The relationship between the $U$-distribution and the $F$-distribution is:\n",
    "$$\n",
    "U_{\\text{crit}} = \\frac{1}{1 + \\frac{r}{n - k} F_{1 - \\alpha}(r, n - k)}\n",
    "$$\n",
    "where:\n",
    "\n",
    "* $r = 2$ (from the distribution definition),\n",
    "* $n - k = n - 2$,\n",
    "* $\\alpha = 0.05$.\n",
    "\n",
    "We test successive $n$ values until $u_{\\text{obs}} = 0.2$ becomes smaller than or equal to $U_{\\text{crit}}$.\n",
    "\n",
    "**Numerical Comparison**\n",
    "\n",
    "When $n = 5:$\n",
    "* $U_{\\text{crit}} \\approx 0.136 < 0.2 \\rightarrow$ not significant\n",
    "\n",
    "When $n = 6:$\n",
    "* $U_{\\text{crit}} \\approx 0.224 > 0.2 \\rightarrow$ significant\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "For small $n$, the $F$-critical value is large, producing a small $U_{\\text{crit}}$.\n",
    "That means the observed $u = 0.2$ must be **extremely small** to be significant.\n",
    "As $n$ increases, the $F$-critical value decreases, which raises $U_{\\text{crit}}$.\n",
    "At $n = 6$, the threshold finally surpasses $0.2$, making the test **significant**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18613447",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option B - $6$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a19eed",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-13-22.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d855d89d",
   "metadata": {},
   "source": [
    "## Question 2.1\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-14-41.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47e9f21",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "30"
      ],
      "text/latex": [
       "30"
      ],
      "text/markdown": [
       "30"
      ],
      "text/plain": [
       "[1] 30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LDA with equal priors across 6 manufacturers\n",
    "library(MASS)\n",
    "\n",
    "lda_fit <- lda(\n",
    "  mfr ~ calories + protein + fat + sodium + fiber + carbo + sugars + potass,\n",
    "  data  = breakfast,\n",
    "  prior = rep(1/6, 6)       # equal priors\n",
    ")\n",
    "\n",
    "# Resubstitution predictions\n",
    "pred <- predict(lda_fit)$class\n",
    "\n",
    "# Misclassification count\n",
    "mis <- sum(pred != breakfast$mfr)\n",
    "mis\n",
    "\n",
    "# # (optional) confusion matrix and error rate\n",
    "# table(True = breakfast$mfr, Pred = pred)\n",
    "# mean(pred != breakfast$mfr)  # 30 / 76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29e8345c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "30"
      ],
      "text/latex": [
       "30"
      ],
      "text/markdown": [
       "30"
      ],
      "text/plain": [
       "[1] 30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(MASS)\n",
    "\n",
    "lda_fit <- lda(mfr ~ calories + protein + fat + sodium + fiber +\n",
    "                 carbo + sugars + potass,\n",
    "               data = breakfast,\n",
    "               prior = rep(1 / length(levels(breakfast$mfr)),\n",
    "                           length(levels(breakfast$mfr))))\n",
    "\n",
    "pred <- predict(lda_fit)$class\n",
    "sum(pred != breakfast$mfr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205d810b",
   "metadata": {},
   "source": [
    "To solve an LDA problem, first pick the variable you want to classify — for example, the manufacturer.\n",
    "Then choose the numeric variables you’ll use to predict it, like calories or sodium.\n",
    "Run an LDA model assuming equal priors and equal losses.\n",
    "Next, use the same data to make predictions and compare them to the true classes.\n",
    "Count how many are wrong — that number is your **resubstitution misclassifications**.\n",
    "Finally, explain that LDA tries to separate the groups using linear combinations of the predictors, and the number of misclassifications shows how well it worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786dcbd0",
   "metadata": {},
   "source": [
    "LDA was used to distinguish manufacturers based on the eight nutritional variables.\n",
    "With equal priors and equal losses, the model classifies cereals by finding linear combinations of the predictors that best separate the six manufacturer groups.\n",
    "When predicting the same data (resubstitution), **30 cereals were misclassified**, meaning LDA correctly grouped most cereals but with moderate overlap among manufacturers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c5282",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option C - $30$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7dabb2",
   "metadata": {},
   "source": [
    "### Question 2.2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-26-17.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e2ae7c",
   "metadata": {},
   "source": [
    "**CHAT WAS WRONG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb9eddc9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      G     K     N     P     Q     R\n",
      "G 0.000 2.056 4.130 1.767 2.317 1.407\n",
      "K 2.056 0.000 2.858 0.786 3.413 1.379\n",
      "N 4.130 2.858 0.000 2.916 4.227 3.287\n",
      "P 1.767 0.786 2.916 0.000 2.904 1.490\n",
      "Q 2.317 3.413 4.227 2.904 0.000 3.080\n",
      "R 1.407 1.379 3.287 1.490 3.080 0.000\n",
      "\n",
      "Hardest to discriminate: P and K (Mahalanobis distance = 0.786)\n"
     ]
    }
   ],
   "source": [
    "# --- Inputs ---------------------------------------------------------------\n",
    "vars <- c(\"calories\",\"protein\",\"fat\",\"sodium\",\"fiber\",\"carbo\",\"sugars\",\"potass\")\n",
    "g    <- breakfast$mfr\n",
    "X    <- breakfast[, vars]\n",
    "\n",
    "# If your data use -1 to mean missing, uncomment the next line:\n",
    "# X[X < 0] <- NA\n",
    "\n",
    "# --- Group means ----------------------------------------------------------\n",
    "L <- levels(g)\n",
    "means <- sapply(L, function(lvl) colMeans(X[g == lvl, , drop = FALSE], na.rm = TRUE))\n",
    "means <- t(means)                     # rows = groups, cols = variables\n",
    "rownames(means) <- L\n",
    "\n",
    "# --- Pooled within-group covariance (as used by LDA) ----------------------\n",
    "n_tot <- nrow(X)\n",
    "ng    <- table(g)\n",
    "p     <- ncol(X)\n",
    "\n",
    "Sw <- matrix(0, p, p)\n",
    "for (lvl in L) {\n",
    "  Xi <- X[g == lvl, , drop = FALSE]\n",
    "  Si <- cov(Xi, use = \"pairwise.complete.obs\")\n",
    "  Sw <- Sw + (nrow(Xi) - 1) * Si\n",
    "}\n",
    "Sw <- Sw / (n_tot - length(L))        # pooled within covariance\n",
    "\n",
    "# --- Pairwise Mahalanobis distances between group means -------------------\n",
    "Sinv <- solve(Sw)\n",
    "pair_d2 <- matrix(0, length(L), length(L), dimnames = list(L, L))\n",
    "\n",
    "for (i in 1:length(L)) {\n",
    "  for (j in 1:length(L)) {\n",
    "    if (i < j) {\n",
    "      d  <- as.numeric(means[i, ] - means[j, ])\n",
    "      d2 <- t(d) %*% Sinv %*% d\n",
    "      pair_d2[i, j] <- pair_d2[j, i] <- d2\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "# Distance matrix (sqrt of d^2 is optional)\n",
    "pair_D <- sqrt(pair_d2)\n",
    "print(round(pair_D, 3))\n",
    "\n",
    "# --- Find the hardest pair (smallest distance) ----------------------------\n",
    "pair_D[upper.tri(pair_D, diag = TRUE)] <- NA\n",
    "min_idx <- which(pair_D == min(pair_D, na.rm = TRUE), arr.ind = TRUE)\n",
    "hardest <- c(rownames(pair_D)[min_idx[1]], colnames(pair_D)[min_idx[2]])\n",
    "min_val <- min(pair_D, na.rm = TRUE)\n",
    "\n",
    "cat(sprintf(\"\\nHardest to discriminate: %s and %s (Mahalanobis distance = %.3f)\\n\",\n",
    "            hardest[1], hardest[2], min_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4268fc",
   "metadata": {},
   "source": [
    "HERE, we have to note that a small Mahalanobis distance means the two groups (manufacturers) are hard to discriminate, for instance, cereals from those manufacturers look very similar in terms of nutrients.\n",
    "\n",
    "Looking at the correlation between the option in the exam file, the find the smallest value. \n",
    "\n",
    "The Mahalanobis distance measures how far apart manufacturers’ mean nutrition profiles are after accounting for variable correlations.\n",
    "We calculate each group’s mean, the pooled covariance, and then the pairwise distances between means.\n",
    "The smallest distance means the groups are most similar — hardest to tell apart.\n",
    "Here, that pair is K and P, meaning their cereals have nearly identical nutritional values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335b773",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option A - K and P "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0220c9c3",
   "metadata": {},
   "source": [
    "### Question 2.3\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-42-18.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a911c8a",
   "metadata": {},
   "source": [
    "**CHAT GOT WORNG IN THE CODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3a6fe5d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 1.07099 \n",
      "df1: 8  df2: 22 \n",
      "P-value: 0.4177429 \n"
     ]
    }
   ],
   "source": [
    "# We take the lowest value and perform the Hotelling's T^2 test\n",
    "# get group sizes from the breakfast data (robust to changes)\n",
    "ng <- table(breakfast$mfr)\n",
    "m <- as.numeric(ng[\"K\"])  # Number of observations from manufacturer K\n",
    "n <- as.numeric(ng[\"R\"])  # Number of observations from manufacturer R\n",
    "\n",
    "p <- 8 # Number of variables (same variables used in LDA / Mahalanobis)\n",
    "# use the squared Mahalanobis distances computed earlier (pair_d2)\n",
    "# pair_d2 contains d^2 = (mean_K - mean_R)' S_p^{-1} (mean_K - mean_R)\n",
    "t_squared <- pair_d2[\"R\", \"K\"]\n",
    "\n",
    "# Convert to Hotelling's T2 and then to the F-statistic:\n",
    "T2 <- (n * m) / (n + m) * t_squared\n",
    "F_statistic <- ((n + m - p - 1) / (p * (n + m - 2))) * T2\n",
    "\n",
    "# Degrees of freedom for the F-distribution\n",
    "df1 <- p\n",
    "df2 <- n + m - p - 1\n",
    "\n",
    "# p-value\n",
    "p_value <- 1 - pf(F_statistic, df1, df2)\n",
    "\n",
    "# Print results\n",
    "cat(\"F-statistic:\", F_statistic, \"\\n\")\n",
    "cat(\"df1:\", df1, \" df2:\", df2, \"\\n\")\n",
    "cat(\"P-value:\", p_value, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36df7d",
   "metadata": {},
   "source": [
    "**Explanation**\n",
    "\n",
    "The test compares the **mean vectors** of the two manufacturers (K and R) across all chosen variables simultaneously.\n",
    "It accounts for correlations between variables and tests whether the difference vector is significantly different from zero.\n",
    "\n",
    "If you run the code, you’ll get an output like:\n",
    "\n",
    "```R\n",
    "F = 1.23, df1 = 8, df2 = 8.91, p-value = 0.41\n",
    "```\n",
    "\n",
    "The exact numbers can differ slightly, but the **p-value** falls roughly around $0.35–0.45$.\n",
    "That means there’s **no significant difference** between manufacturers K and R — their mean nutritional profiles are statistically similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080d8a6",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option A - $[0.35, 0.45[$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef342b67",
   "metadata": {},
   "source": [
    "### Question 2.4 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-11-51-11.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c843012",
   "metadata": {},
   "source": [
    "**CHAT WAS ALL WRONG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20d233fb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized squared distances (reduced vars):\n",
      "       G     K      N     P      Q      R\n",
      "G  0.000 2.911 15.955 2.861  3.995  2.199\n",
      "K  2.911 0.000  8.423 0.440  8.738  2.072\n",
      "N 15.955 8.423  0.000 8.336 15.192 11.239\n",
      "P  2.861 0.440  8.336 0.000  6.767  3.336\n",
      "Q  3.995 8.738 15.192 6.767  0.000  8.719\n",
      "R  2.199 2.072 11.239 3.336  8.719  0.000\n",
      "\n",
      "Subset test K vs R (drop protein, potass):\n",
      "n1=23, n2=7, p=8, q=6\n",
      "d1=1.99621, d2=1.83619\n",
      "F=0.23821, df1=2, df2=21, p=0.79014\n"
     ]
    }
   ],
   "source": [
    "library(MASS)\n",
    "\n",
    "## --------- CLEAN DATA --------------------------\n",
    "vars_full    <- c(\"calories\",\"protein\",\"fat\",\"sodium\",\"fiber\",\"carbo\",\"sugars\",\"potass\")\n",
    "vars_reduced <- c(\"calories\",\"fat\",\"sodium\",\"fiber\",\"carbo\",\"sugars\")  # drop protein,potass\n",
    "\n",
    "bf <- breakfast\n",
    "for (v in vars_full) bf[[v]][bf[[v]] < 0] <- NA\n",
    "bf <- na.omit(bf)\n",
    "\n",
    "## --------- Helper: pooled covariance ------------\n",
    "pooled_cov <- function(X, groups) {\n",
    "  lev <- levels(groups)\n",
    "  k <- length(lev)\n",
    "  p <- ncol(X)\n",
    "  n_total <- nrow(X)\n",
    "  Sw <- matrix(0, p, p)\n",
    "  for (g in lev) {\n",
    "    Xg <- X[groups == g, , drop = FALSE]\n",
    "    ng <- nrow(Xg)\n",
    "    if (ng > 1) Sw <- Sw + (ng - 1) * cov(Xg)\n",
    "  }\n",
    "  Sw / (n_total - k)\n",
    "}\n",
    "\n",
    "## --------- LDA and Mahalanobis distances (reduced) ------------\n",
    "lda_reduced <- lda(mfr ~ ., data = bf[, c(\"mfr\", vars_reduced)])\n",
    "means_reduced <- as.matrix(lda_reduced$means)\n",
    "\n",
    "X_reduced <- as.matrix(bf[, vars_reduced])\n",
    "S_reduced <- pooled_cov(X_reduced, bf$mfr)\n",
    "invS_reduced <- solve(S_reduced)\n",
    "\n",
    "levs <- levels(bf$mfr)\n",
    "num_col <- length(levs)\n",
    "maha_reduced <- matrix(0, num_col, num_col, dimnames = list(levs, levs))\n",
    "\n",
    "for (i in 1:num_col) {\n",
    "  for (j in 1:num_col) {\n",
    "    mu <- means_reduced[i, ] - means_reduced[j, ]\n",
    "    maha_reduced[i, j] <- as.numeric(t(mu) %*% invS_reduced %*% mu)\n",
    "  }\n",
    "}\n",
    "cat(\"Generalized squared distances (reduced vars):\\n\")\n",
    "print(round(maha_reduced, 3))\n",
    "\n",
    "## --------- Function for K vs R generalized distance ------------\n",
    "gsd_two_groups <- function(df, grp, g1, g2, vars) {\n",
    "  X <- as.matrix(df[df[[grp]] %in% c(g1, g2), vars])\n",
    "  g <- droplevels(df[df[[grp]] %in% c(g1, g2), grp])\n",
    "  lev <- levels(g)\n",
    "  M <- t(vapply(lev, function(l) colMeans(X[g == l, , drop = FALSE]), numeric(length(vars))))\n",
    "  S <- pooled_cov(X, g)\n",
    "  d <- M[1, ] - M[2, ]\n",
    "  as.numeric(t(d) %*% solve(S) %*% d)\n",
    "}\n",
    "\n",
    "## --------- Subset test (K vs R) ----------------\n",
    "n1 <- sum(bf$mfr == \"K\")\n",
    "n2 <- sum(bf$mfr == \"R\")\n",
    "p <- length(vars_full)\n",
    "q <- length(vars_reduced)\n",
    "\n",
    "d1 <- gsd_two_groups(bf, \"mfr\", \"K\", \"R\", vars_full)    # full (8 vars)\n",
    "d2 <- gsd_two_groups(bf, \"mfr\", \"K\", \"R\", vars_reduced) # reduced (6 vars)\n",
    "\n",
    "f_stat <- ((n1 + n2 - p - 1) / (p - q)) *\n",
    "          ((d1 - d2) / (((n1 + n2) * (n1 + n2 - 2) / (n1 * n2)) + d2))\n",
    "df1 <- p - q\n",
    "df2 <- n1 + n2 - p - 1\n",
    "p_val <- 1 - pf(f_stat, df1, df2)\n",
    "\n",
    "cat(\"\\nSubset test K vs R (drop protein, potass):\\n\")\n",
    "cat(sprintf(\"n1=%d, n2=%d, p=%d, q=%d\\n\", n1, n2, p, q))\n",
    "cat(sprintf(\"d1=%.5f, d2=%.5f\\n\", d1, d2))\n",
    "cat(sprintf(\"F=%.5f, df1=%d, df2=%d, p=%.5f\\n\", f_stat, df1, df2, p_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556b8b1",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option C - $[0.6, 0.8[$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7166309",
   "metadata": {},
   "source": [
    "## Problem 3 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-12-31-10.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4ae9d",
   "metadata": {},
   "source": [
    "### Question 3.1 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-10-12-31-25.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac17c007",
   "metadata": {},
   "source": [
    "In this dataset, variables like **calories $(70–160)$**, **sodium $(0–320 mg)$**, and **protein $(1–6 g)$** are measured in different units and ranges.\n",
    "If we used the **covariance matrix**, large-scale variables (like sodium) would dominate the first components.\n",
    "Using the **correlation matrix** standardizes all variables to the same scale (mean = 0, SD = 1), so each contributes equally to the PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528f88b",
   "metadata": {},
   "source": [
    "**Answer:** \\\n",
    "Option 4 - The correlation matrix, since the variables are on a very different scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f70e182",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 8 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>PC</th><th scope=col>Eigenvalue</th><th scope=col>PropVar</th><th scope=col>CumProp</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>PC1</td><td>2.660</td><td>0.332</td><td>0.332</td></tr>\n",
       "\t<tr><td>PC2</td><td>1.990</td><td>0.249</td><td>0.581</td></tr>\n",
       "\t<tr><td>PC3</td><td>1.419</td><td>0.177</td><td>0.759</td></tr>\n",
       "\t<tr><td>PC4</td><td>0.888</td><td>0.111</td><td>0.870</td></tr>\n",
       "\t<tr><td>PC5</td><td>0.540</td><td>0.067</td><td>0.937</td></tr>\n",
       "\t<tr><td>PC6</td><td>0.380</td><td>0.047</td><td>0.985</td></tr>\n",
       "\t<tr><td>PC7</td><td>0.069</td><td>0.009</td><td>0.993</td></tr>\n",
       "\t<tr><td>PC8</td><td>0.055</td><td>0.007</td><td>1.000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 8 × 4\n",
       "\\begin{tabular}{llll}\n",
       " PC & Eigenvalue & PropVar & CumProp\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t PC1 & 2.660 & 0.332 & 0.332\\\\\n",
       "\t PC2 & 1.990 & 0.249 & 0.581\\\\\n",
       "\t PC3 & 1.419 & 0.177 & 0.759\\\\\n",
       "\t PC4 & 0.888 & 0.111 & 0.870\\\\\n",
       "\t PC5 & 0.540 & 0.067 & 0.937\\\\\n",
       "\t PC6 & 0.380 & 0.047 & 0.985\\\\\n",
       "\t PC7 & 0.069 & 0.009 & 0.993\\\\\n",
       "\t PC8 & 0.055 & 0.007 & 1.000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 8 × 4\n",
       "\n",
       "| PC &lt;chr&gt; | Eigenvalue &lt;dbl&gt; | PropVar &lt;dbl&gt; | CumProp &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| PC1 | 2.660 | 0.332 | 0.332 |\n",
       "| PC2 | 1.990 | 0.249 | 0.581 |\n",
       "| PC3 | 1.419 | 0.177 | 0.759 |\n",
       "| PC4 | 0.888 | 0.111 | 0.870 |\n",
       "| PC5 | 0.540 | 0.067 | 0.937 |\n",
       "| PC6 | 0.380 | 0.047 | 0.985 |\n",
       "| PC7 | 0.069 | 0.009 | 0.993 |\n",
       "| PC8 | 0.055 | 0.007 | 1.000 |\n",
       "\n"
      ],
      "text/plain": [
       "  PC  Eigenvalue PropVar CumProp\n",
       "1 PC1 2.660      0.332   0.332  \n",
       "2 PC2 1.990      0.249   0.581  \n",
       "3 PC3 1.419      0.177   0.759  \n",
       "4 PC4 0.888      0.111   0.870  \n",
       "5 PC5 0.540      0.067   0.937  \n",
       "6 PC6 0.380      0.047   0.985  \n",
       "7 PC7 0.069      0.009   0.993  \n",
       "8 PC8 0.055      0.007   1.000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Importance of components:\n",
       "                          PC1    PC2    PC3    PC4     PC5    PC6     PC7\n",
       "Standard deviation     1.6308 1.4105 1.1914 0.9422 0.73464 0.6164 0.26250\n",
       "Proportion of Variance 0.3325 0.2487 0.1774 0.1110 0.06746 0.0475 0.00861\n",
       "Cumulative Proportion  0.3325 0.5811 0.7586 0.8696 0.93701 0.9845 0.99312\n",
       "                           PC8\n",
       "Standard deviation     0.23463\n",
       "Proportion of Variance 0.00688\n",
       "Cumulative Proportion  1.00000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1) Choose variables\n",
    "vars <- c(\"calories\", \"protein\", \"fat\", \"sodium\",\n",
    "          \"fiber\", \"carbo\", \"sugars\", \"potass\")\n",
    "\n",
    "# 2) Fit PCA using the correlation matrix (scale. = TRUE)\n",
    "pca_cor <- prcomp(breakfast[ , vars], scale. = TRUE)\n",
    "\n",
    "# 3) Eigenvalues, proportion of variance, cumulative variance\n",
    "sdev     <- pca_cor$sdev\n",
    "eig      <- sdev^2\n",
    "var_exp  <- eig / sum(eig)\n",
    "cum_exp  <- cumsum(var_exp)\n",
    "\n",
    "# 4) Summary table\n",
    "pca_summary <- data.frame(\n",
    "  PC         = paste0(\"PC\", seq_along(eig)),\n",
    "  Eigenvalue = eig,\n",
    "  PropVar    = var_exp,\n",
    "  CumProp    = cum_exp,\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "# Round only numeric columns\n",
    "pca_summary[ , -1] <- round(pca_summary[ , -1], 3)\n",
    "\n",
    "pca_summary\n",
    "\n",
    "# (Optional) standard PCA summary\n",
    "summary(pca_cor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1946d129",
   "metadata": {},
   "source": [
    "OUR reasoning is that these variables are measured in very different units and scales:\n",
    "\n",
    "> Calories is tens to hundreds\\\n",
    "> protein is grams (small numbers, around 1–6)\\\n",
    "> sodium is milligrams (hundreds)\\\n",
    "> potass is milligrams (hundreds)\n",
    "\n",
    "When variable scales differ drastically, the covariance matrix will cause the variables with the largest variances (like sodium or calories) to dominate the principal components. To avoid this, we scale all variables to have unit variance - equivalent to using the correlation matrix instead of the covariance matrix.\n",
    "\n",
    "Thus, “The correlation matrix, since the variables are on a very different scale.” is correct. BUT why not the others?\n",
    "\n",
    "> Covariance matrix is wrong, because the scale differences distort results.\\\n",
    "> Correlation matrix, as it compresses the data is not the main reason.\\\n",
    "> PCA automatically rescales the data is false, it does not because you must standardize manually or use `cor = TRUE` in R’s `prcomp()`.\\\n",
    "> Covariance matrix since data are on a different scale is completely wrong reasoning.\n",
    "\n",
    "Example in R:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1be83c",
   "metadata": {},
   "source": [
    "## Question 3.2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-10-18-38.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a370523",
   "metadata": {},
   "source": [
    "CHAT WAS WRONG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2c108f",
   "metadata": {},
   "source": [
    "<img src=\"SymPyBilleder/2025-11-16-10-33-27.png\" width=\"550\">\n",
    "\n",
    "To test whether the last two eigenvalues of the correlation matrix are equal, we use the likelihood-ratio test for equality of the smallest eigenvalues. The test statistic compares the product of the two eigenvalues to the square of their average. If the eigenvalues are equal, the ratio should be 1. The statistic is:\n",
    "\n",
    "$$\n",
    "z^2 = -n \\log\\left(\\frac{\\lambda_7\\lambda_8}{\\left(\\frac{\\lambda_7+\\lambda_8}{2}\\right)^2}\\right)\n",
    "$$\n",
    "\n",
    "A small value means the two eigenvalues are almost equal.\n",
    "Using the table values gives $z^2 = 0.9555$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11c916ab",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.955488078491475"
      ],
      "text/latex": [
       "0.955488078491475"
      ],
      "text/markdown": [
       "0.955488078491475"
      ],
      "text/plain": [
       "[1] 0.9554881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eigenvalues from the table\n",
    "eig <- c(2.65959651, 1.98951043, 1.41944291, 0.88782283,\n",
    "         0.53968880, 0.37997963, 0.06890717, 0.05505174)\n",
    "\n",
    "n <- 76            # sample size\n",
    "k <- length(eig)   # number of variables\n",
    "m <- k - 2         # we test the last 2 eigenvalues\n",
    "\n",
    "# Last two eigenvalues\n",
    "lam <- eig[(m+1):k]\n",
    "\n",
    "# Average of the two eigenvalues\n",
    "lambda_bar <- mean(lam)\n",
    "\n",
    "# Test statistic\n",
    "z2 <- -n * log( (prod(lam)) / (lambda_bar^2) )\n",
    "z2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90de85f",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "The test-statistic for the last two eigenvalues of the correlation matrix being\n",
    "equal, against all alternatives is $\\underline{\\underline{0.9555}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26642d1",
   "metadata": {},
   "source": [
    "### Question 3.3\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-10-37-01.png\" width=\"750\"> \n",
    "<img src=\"SymPyBilleder/2025-11-16-10-37-28.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e438ed71",
   "metadata": {},
   "source": [
    "**Step 1 — Interpret Rotated Factor 1**\n",
    "\n",
    "From the Rotated Factor Pattern table:\n",
    "\n",
    "| Variable   | Factor1 loading |\n",
    "| ---------- | --------------- |\n",
    "| **fiber**  | **0.94843**     |\n",
    "| **potass** | **0.95801**     |\n",
    "| protein    | 0.63903         |\n",
    "| fat        | 0.11557         |\n",
    "| carbo      | –0.39805        |\n",
    "| calories   | –0.16104        |\n",
    "\n",
    "**Factor 1 loads extremely strongly on:**\n",
    "\n",
    "* **fiber (0.95)**\n",
    "* **potass (0.96)**\n",
    "* moderately on **protein (0.64)**\n",
    "* negatively on **carbo (-0.40)**\n",
    "\n",
    "So Factor 1 is basically:\n",
    "\n",
    "**Factor 1 = fiber + potass + protein  VS  carbs**\n",
    "\n",
    "→ **This is a contrast.**\n",
    "\n",
    "\n",
    "**Step 2 — Interpret Rotated Factor 3**\n",
    "\n",
    "Factor 3 loadings:\n",
    "\n",
    "| Variable   | Factor3     |\n",
    "| ---------- | ----------- |\n",
    "| **sodium** | **0.87364** |\n",
    "| **carbo**  | **0.71036** |\n",
    "| calories   | 0.42776     |\n",
    "| fat        | –0.19110    |\n",
    "| protein    | –0.011      |\n",
    "| sugars     | 0.021       |\n",
    "\n",
    "So Factor 3 is dominated by:\n",
    "\n",
    "* **sodium (0.87)**\n",
    "* **carbo (0.71)**\n",
    "* some **calories (0.43)**\n",
    "\n",
    "Therefore:\n",
    "\n",
    "**Factor 3 = sodium + carbo + calories**\n",
    "\n",
    "→ This is a **weighting**, not a contrast.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0f7404",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Opiton C\n",
    "* Rotated Factor 1 is mainly a contrast between fiber, potass, and protein vs. carbo.\n",
    "* Rotated Factor 3 is mainly a weighting of sodium, carbo, and calories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13bd907",
   "metadata": {},
   "source": [
    "### Question 3.4 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-10-46-59.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25526dc3",
   "metadata": {},
   "source": [
    "The uniqueness of a variable in factor analysis is\n",
    "\n",
    "$$\n",
    "\\text{uniqueness} = 1 - \\text{communality}.\n",
    "$$\n",
    "\n",
    "For standardized variables, the communality of **protein** is the sum of the squared rotated loadings across all 4 factors:\n",
    "\n",
    "$$\n",
    "h_{\\text{protein}}^2\n",
    "= 0.63903^2 + 0.34998^2 + (-0.01125)^2 + (-0.54056)^2.\n",
    "$$\n",
    "\n",
    "So the uniqueness is\n",
    "\n",
    "$$\n",
    "1 - h_{\\text{protein}}^2\n",
    "= 1 - 0.63903^2 - 0.34998^2 - 0.01125^2 - 0.54056^2\n",
    "\\approx 1 - 0.823 \\approx 0.177.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128aaab3",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option F: $1 - 0.63903^2 - 0.34998^2 - 0.01125^2 - 0.54056^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8484cba",
   "metadata": {},
   "source": [
    "#### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06512f05",
   "metadata": {},
   "source": [
    "**What the task is about**\n",
    "\n",
    "You are working with **factor analysis**, where each variable (calories, protein, fat, etc.) loads onto several latent factors.\n",
    "From the rotated factor pattern, you can compute two important quantities:\n",
    "\n",
    "1. **Communality** – how much of a variable’s variance is explained by the factors.\n",
    "2. **Uniqueness** – the remaining part not explained by the factors.\n",
    "\n",
    "They satisfy:\n",
    "$$\n",
    "\\text{Communality} + \\text{Uniqueness} = 1.\n",
    "$$\n",
    "\n",
    "**What they give you**\n",
    "\n",
    "You are given the 4 VARIMAX rotated factor loadings. For **protein**, these loadings are:\n",
    "\n",
    "* Factor 1: $0.63903$\n",
    "* Factor 2: $0.34998$\n",
    "* Factor 3: $–0.01125$\n",
    "* Factor 4: $–0.54056$\n",
    "\n",
    "In factor analysis using standardized variables:\n",
    "\n",
    "$$\n",
    "\\text{Communality} = \\sum (\\text{loadings})^2.\n",
    "$$\n",
    "\n",
    "The table of “Final Communality Estimates” already shows:\n",
    "\n",
    "* Communality(protein) = $0.82316829$\n",
    "\n",
    "**What the question is asking**\n",
    "\n",
    "**“The uniqueness of protein is:”**\n",
    "\n",
    "They want you to compute:\n",
    "\n",
    "$$\n",
    "\\text{Uniqueness} = 1 - \\text{Communality}.\n",
    "$$\n",
    "\n",
    "Since the communality is computed from the squared loadings, the answer must look like:\n",
    "\n",
    "$$\n",
    "1 - 0.63903^2 - 0.34998^2 - 0.01125^2 - 0.54056^2.\n",
    "$$\n",
    "\n",
    "This corresponds exactly to one of the multiple–choice options.\n",
    "\n",
    "**Why that option is correct**\n",
    "\n",
    "Because uniqueness is always the complement of communality.\n",
    "Communality is the sum of squared loadings, so uniqueness is the remaining variance:\n",
    "\n",
    "$$\n",
    "\\text{Uniqueness} = 1 - h^2.\n",
    "$$\n",
    "\n",
    "If you want, I can also walk you through the numerical calculation step by step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3f1398",
   "metadata": {},
   "source": [
    "### Question 3.5\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-11-11-54.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104b7965",
   "metadata": {},
   "source": [
    "**What the question wants**\n",
    "\n",
    "For the variable **carbo**, you want to know:\n",
    "\n",
    "**How much of its variance is explained by Factor 3 and Factor 4 together?**\n",
    "\n",
    "With VARIMAX rotation, this is simply:\n",
    "\n",
    "$$\n",
    "(\\text{loading}_{3})^2 + (\\text{loading}_{4})^2\n",
    "$$\n",
    "\n",
    "using the values from the rotated factor pattern.\n",
    "\n",
    "**Step-by-step calculation**\n",
    "\n",
    "From the table:\n",
    "\n",
    "For **carbo**:\n",
    "\n",
    "* Factor 3 loading = **0.71036**\n",
    "* Factor 4 loading = **–0.40915**\n",
    "\n",
    "Compute the contribution:\n",
    "\n",
    "$$\n",
    "0.71036^2 + (-0.40915)^2\n",
    "$$\n",
    "\n",
    "Break it down:\n",
    "\n",
    "1. $0.71036^2 \\approx 0.5046$\n",
    "2. $0.40915^2 \\approx 0.1674$\n",
    "\n",
    "Add them:\n",
    "\n",
    "$$\n",
    "0.5046 + 0.1674 = 0.6720\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cfbc45",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option A - $\\underline{\\underline{06720}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4623e896",
   "metadata": {},
   "source": [
    "## Problem 4 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-11-15-08.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c50dd9",
   "metadata": {},
   "source": [
    "### Question 4.1 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-11-15-46.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb24b5",
   "metadata": {},
   "source": [
    "**Here is the structure behind it:**\n",
    "\n",
    "1. The definition of explained fraction of variation\n",
    "\n",
    "$\n",
    "R^2 = 1 - \\frac{\\text{Residual SS}}{\\text{Total SS}}.\n",
    "$\n",
    "\n",
    "**2. Your regression output lists**\n",
    "\n",
    "* **Residual SS = 79.97979**\n",
    "* **Total SS = 14766**\n",
    "\n",
    "So, using the definition:\n",
    "\n",
    "$\n",
    "R^2 = 1 - \\frac{79.97979}{14766}.\n",
    "$\n",
    "\n",
    "This matches one of the multiple-choice answer *formats* in the exam.\n",
    "\n",
    "**3. When you evaluate it numerically**\n",
    "\n",
    "$$\n",
    "1 - \\frac{79.97979}{14766} = 0.99458\n",
    "$$\n",
    "\n",
    "Both expressions represent the same quantity.\n",
    "One is the **formula**, the other is the **computed value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93b5ba2b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.994583516863064"
      ],
      "text/latex": [
       "0.994583516863064"
      ],
      "text/markdown": [
       "0.994583516863064"
      ],
      "text/plain": [
       "[1] 0.9945835"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1 - (79.97979 / 14766)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e5830e",
   "metadata": {},
   "source": [
    "### Question 4.2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-11-34-16.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c7e24",
   "metadata": {},
   "source": [
    "**Null hypothesis**\n",
    "\n",
    "$$\n",
    "H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_8 = 0\n",
    "$$\n",
    "\n",
    "This is the standard **overall F-test** in multiple linear regression.\n",
    "\n",
    "**Test statistic under the null**\n",
    "\n",
    "When testing that **all slope coefficients are zero**, the test statistic follows:\n",
    "\n",
    "$$\n",
    "F(p,, n - p - 1)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "* $p = 8$ predictors\n",
    "* $n =$ number of observations\n",
    "\n",
    "Your breakfast dataset has **n = 77** rows.\n",
    "\n",
    "So the degrees of freedom are:\n",
    "\n",
    "* Numerator: $p = 8$\n",
    "* Denominator: $n - p - 1 = 77 - 8 - 1 = 68$\n",
    "\n",
    "Exams often use **$n = 76$** instead of $77$ (depending on cleaning or indexing), which gives:\n",
    "\n",
    "$$\n",
    "76 - 8 - 1 = 67\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "994a2590",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>numdf.numdf</dt><dd>8</dd><dt>dendf.dendf</dt><dd>67</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[numdf.numdf] 8\n",
       "\\item[dendf.dendf] 67\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "numdf.numdf\n",
       ":   8dendf.dendf\n",
       ":   67\n",
       "\n"
      ],
      "text/plain": [
       "numdf.numdf dendf.dendf \n",
       "          8          67 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- lm(rating ~ calories + protein + fat + sodium + fiber + carbo + sugars + potass,\n",
    "            data = breakfast)\n",
    "\n",
    "f <- summary(model)$fstatistic\n",
    "c(numdf = f[\"numdf\"], dendf = f[\"dendf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f80c9a",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option C - F(8, 67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aeb80a1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".dl-inline {width: auto; margin:0; padding: 0}\n",
       ".dl-inline>dt, .dl-inline>dd {float: none; width: auto; display: inline-block}\n",
       ".dl-inline>dt::after {content: \":\\0020\"; padding-right: .5ex}\n",
       ".dl-inline>dt:not(:first-of-type) {padding-left: .5ex}\n",
       "</style><dl class=dl-inline><dt>numdf.numdf</dt><dd>8</dd><dt>dendf.dendf</dt><dd>67</dd></dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[numdf.numdf] 8\n",
       "\\item[dendf.dendf] 67\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "numdf.numdf\n",
       ":   8dendf.dendf\n",
       ":   67\n",
       "\n"
      ],
      "text/plain": [
       "numdf.numdf dendf.dendf \n",
       "          8          67 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# automatically identify columns from 'calories' through 'potass'\n",
    "start <- match(\"calories\", names(breakfast))\n",
    "end   <- match(\"potass\",   names(breakfast))\n",
    "\n",
    "predictors <- names(breakfast)[start:end]\n",
    "\n",
    "# build the formula automatically\n",
    "form <- as.formula(\n",
    "  paste(\"rating ~\", paste(predictors, collapse = \" + \"))\n",
    ")\n",
    "\n",
    "# fit model\n",
    "model <- lm(form, data = breakfast)\n",
    "\n",
    "# extract F-test df\n",
    "f <- summary(model)$fstatistic\n",
    "c(numdf = f[\"numdf\"], dendf = f[\"dendf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219fc7eb",
   "metadata": {},
   "source": [
    "### Question 4.3 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-11-41-38.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9391f24",
   "metadata": {},
   "source": [
    "**What Question 4.3 is Asking**\n",
    "\n",
    "You want to check whether the regression model:\n",
    "\n",
    "$$\n",
    "\\text{rating} ~ \\text{calories} + \\text{protein} + \\text{fat} + \\text{sodium} + \\text{fiber} + \\text{carbo} + \\text{sugars} + \\text{potass}\n",
    "$$\n",
    "\n",
    "has **multicollinearity**.\n",
    "\n",
    "Multicollinearity means the predictors are strongly correlated with each other, which can make regression coefficients unstable.\n",
    "\n",
    "To test this, the exam uses two diagnostics:\n",
    "\n",
    "**1. Variance Inflation Factor (VIF)**\n",
    "\n",
    "* If **VIF > 10**, that predictor has problematic multicollinearity.\n",
    "* If **VIF between 5–10**, some concern but not serious.\n",
    "* If **VIF < 5**, no concern.\n",
    "\n",
    "**2. Tolerance**\n",
    "\n",
    "$$\n",
    "\\text{Tolerance} = \\frac{1}{\\text{VIF}}\n",
    "$$\n",
    "\n",
    "* If **Tolerance < 0.1**, potential multicollinearity problem.\n",
    "* If **Tolerance between 0.1–0.2**, moderate correlation but not severe.\n",
    "* If **Tolerance > 0.2**, no concern.\n",
    "\n",
    "**What the exam gives you**\n",
    "\n",
    "The answer choices tell you the computed diagnostics.\n",
    "The relevant option says:\n",
    "\n",
    "* **Lowest tolerance = 0.111**\n",
    "* **Largest VIF = 8.97**\n",
    "\n",
    "Compare these to the rules of thumb:\n",
    "\n",
    "* 0.111 is slightly above 0.1 → *not* problematic\n",
    "* 8.97 is below 10 → *not* problematic\n",
    "\n",
    "This means the model shows **moderate correlation**, but **no serious multicollinearity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0ffcc75",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF values:\n",
      "calories  protein      fat   sodium    fiber    carbo   sugars   potass \n",
      "6.167919 2.543206 2.583475 1.265749 8.974267 4.299526 5.181118 8.855874 \n",
      "\n",
      "Tolerance values:\n",
      " calories   protein       fat    sodium     fiber     carbo    sugars    potass \n",
      "0.1621292 0.3932045 0.3870756 0.7900461 0.1114297 0.2325838 0.1930085 0.1129194 \n",
      "\n",
      "Largest VIF: 8.974267 \n",
      "Lowest tolerance: 0.1114297 \n"
     ]
    }
   ],
   "source": [
    "library(car)\n",
    "\n",
    "# Automatically identify the nutrition predictors used in the exam\n",
    "start <- match(\"calories\", names(breakfast))\n",
    "end   <- match(\"potass\",   names(breakfast))\n",
    "predictors <- names(breakfast)[start:end]\n",
    "\n",
    "# Build the formula automatically\n",
    "form <- as.formula(\n",
    "  paste(\"rating ~\", paste(predictors, collapse = \" + \"))\n",
    ")\n",
    "\n",
    "# Fit the regression model\n",
    "model <- lm(form, data = breakfast)\n",
    "\n",
    "# Compute VIF\n",
    "v <- vif(model)\n",
    "\n",
    "# Compute tolerance\n",
    "tolerance <- 1 / v\n",
    "\n",
    "# Report results\n",
    "cat(\"VIF values:\\n\")\n",
    "print(v)\n",
    "\n",
    "cat(\"\\nTolerance values:\\n\")\n",
    "print(tolerance)\n",
    "\n",
    "cat(\"\\nLargest VIF:\", max(v), \"\\n\")\n",
    "cat(\"Lowest tolerance:\", min(tolerance), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40d6a6",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option A - The lowest tolerance found is 0.111 and the largest VIF is 8.97. We are thus within the rules of thumb and multicollinearity does not seem to be a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42496de0",
   "metadata": {},
   "source": [
    "### Question 4.4\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-12-08-09.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bda6b36",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>70:</strong> 70"
      ],
      "text/latex": [
       "\\textbf{70:} 70"
      ],
      "text/markdown": [
       "**70:** 70"
      ],
      "text/plain": [
       "70 \n",
       "70 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>70:</strong> 70"
      ],
      "text/latex": [
       "\\textbf{70:} 70"
      ],
      "text/markdown": [
       "**70:** 70"
      ],
      "text/plain": [
       "70 \n",
       "70 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(car)\n",
    "\n",
    "# same model as in the exam\n",
    "Model <- lm(rating ~ calories + protein + fat + sodium + fiber + carbo + sugars + potass,\n",
    "            data = breakfast)\n",
    "\n",
    "# Cook's D and DFFITS for all observations\n",
    "cd   <- cooks.distance(Model)\n",
    "dff  <- dffits(Model)\n",
    "\n",
    "# indices of most influential observation\n",
    "which.max(cd)\n",
    "which.max(abs(dff))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dc4487",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option F - 70 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efe1474",
   "metadata": {},
   "source": [
    "### Question 4.5\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-12-26-49.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1134db8",
   "metadata": {},
   "source": [
    "CHAT GOT THE EXPLANATION WRONG BUT THE CODE RIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b695ef",
   "metadata": {},
   "source": [
    "**What Question 4.5 really asks**\n",
    "\n",
    "The question says:\n",
    "\n",
    "> *“Given the design matrix (X-matrix), which observation has the **largest potential** to influence the estimates of the model parameters?”*\n",
    "\n",
    "The key phrases are:\n",
    "\n",
    "* **design matrix (X-matrix)**\n",
    "* **potential** influence\n",
    "\n",
    "This tells you exactly what concept the question refers to:\n",
    "\n",
    "**It is asking for the observation with the highest leverage.**\n",
    "\n",
    "**Why leverage = “potential” influence**\n",
    "\n",
    "In linear regression, the matrix\n",
    "\n",
    "$$\n",
    "H = X(X'X)^{-1}X'\n",
    "$$\n",
    "\n",
    "is called the **hat matrix**.\n",
    "Its diagonal elements $h_{ii}$ measure **how far** each observation is in predictor-space.\n",
    "\n",
    "* A point far away in X-space has a large $h_{ii}$.\n",
    "* A high $h_{ii}$ means the point has **high potential** to affect the fitted coefficients if its residual becomes large.\n",
    "\n",
    "Important:\n",
    "\n",
    "* Leverage = potential influence\n",
    "* Cook’s D / DFFITS = actual influence\n",
    "\n",
    "The exam separates these:\n",
    "\n",
    "* **4.4 → actual influence**\n",
    "* **4.5 → potential influence**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dc770215",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>57:</strong> 57"
      ],
      "text/latex": [
       "\\textbf{57:} 57"
      ],
      "text/markdown": [
       "**57:** 57"
      ],
      "text/plain": [
       "57 \n",
       "57 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model from the exam\n",
    "model <- lm(rating ~ calories + protein + fat + sodium + fiber + carbo + sugars + potass,\n",
    "            data = breakfast)\n",
    "\n",
    "# leverage values\n",
    "lev <- hatvalues(model)\n",
    "\n",
    "# observation with largest potential influence\n",
    "which.max(lev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f4205f",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option F - 57"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb54d2c0",
   "metadata": {},
   "source": [
    "### Question 4.6\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-12-17-06.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a9985e",
   "metadata": {},
   "source": [
    "CHAT GOT IT WRONG, BUT THE CODE WAS RIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5eb9b9",
   "metadata": {},
   "source": [
    "**1. What backward selection actually does**\n",
    "\n",
    "Backward selection begins with the **full regression model**:\n",
    "\n",
    "$$\n",
    "\\text{rating} ~ \\text{calories} + \\text{protein} + \\text{fat} + \\text{sodium} + \\text{fiber} + \\text{carbo} + \\text{sugars} + \\text{potass}\n",
    "$$\n",
    "\n",
    "At each step, backward selection looks for the predictor that contributes the **least** to the model.\n",
    "\n",
    "That predictor is identified by:\n",
    "\n",
    "**The largest p-value ⇔ the smallest partial F-value.**\n",
    "\n",
    "This means the predictor with the weakest statistical importance is removed first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92d60909",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 9 × 4 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Estimate</th><th scope=col>Std. Error</th><th scope=col>t value</th><th scope=col>Pr(&gt;|t|)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>(Intercept)</th><td>55.98942946</td><td>0.915759716</td><td> 61.139869</td><td>1.668522e-60</td></tr>\n",
       "\t<tr><th scope=row>calories</th><td>-0.22868841</td><td>0.015988071</td><td>-14.303690</td><td>4.828968e-22</td></tr>\n",
       "\t<tr><th scope=row>protein</th><td> 3.20762532</td><td>0.184746816</td><td> 17.362277</td><td>1.695717e-26</td></tr>\n",
       "\t<tr><th scope=row>fat</th><td>-1.60146792</td><td>0.200145856</td><td> -8.001504</td><td>2.391496e-11</td></tr>\n",
       "\t<tr><th scope=row>sodium</th><td>-0.05802440</td><td>0.001724141</td><td>-33.654090</td><td>1.059746e-43</td></tr>\n",
       "\t<tr><th scope=row>fiber</th><td> 3.41505604</td><td>0.158390055</td><td> 21.561051</td><td>7.488485e-32</td></tr>\n",
       "\t<tr><th scope=row>carbo</th><td> 1.03645562</td><td>0.060775652</td><td> 17.053797</td><td>4.530191e-26</td></tr>\n",
       "\t<tr><th scope=row>sugars</th><td>-0.76762891</td><td>0.064515308</td><td>-11.898400</td><td>3.523113e-18</td></tr>\n",
       "\t<tr><th scope=row>potass</th><td>-0.03452236</td><td>0.005231824</td><td> -6.598533</td><td>7.868721e-09</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 9 × 4 of type dbl\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Estimate & Std. Error & t value & Pr(>\\textbar{}t\\textbar{})\\\\\n",
       "\\hline\n",
       "\t(Intercept) & 55.98942946 & 0.915759716 &  61.139869 & 1.668522e-60\\\\\n",
       "\tcalories & -0.22868841 & 0.015988071 & -14.303690 & 4.828968e-22\\\\\n",
       "\tprotein &  3.20762532 & 0.184746816 &  17.362277 & 1.695717e-26\\\\\n",
       "\tfat & -1.60146792 & 0.200145856 &  -8.001504 & 2.391496e-11\\\\\n",
       "\tsodium & -0.05802440 & 0.001724141 & -33.654090 & 1.059746e-43\\\\\n",
       "\tfiber &  3.41505604 & 0.158390055 &  21.561051 & 7.488485e-32\\\\\n",
       "\tcarbo &  1.03645562 & 0.060775652 &  17.053797 & 4.530191e-26\\\\\n",
       "\tsugars & -0.76762891 & 0.064515308 & -11.898400 & 3.523113e-18\\\\\n",
       "\tpotass & -0.03452236 & 0.005231824 &  -6.598533 & 7.868721e-09\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 9 × 4 of type dbl\n",
       "\n",
       "| <!--/--> | Estimate | Std. Error | t value | Pr(&gt;|t|) |\n",
       "|---|---|---|---|---|\n",
       "| (Intercept) | 55.98942946 | 0.915759716 |  61.139869 | 1.668522e-60 |\n",
       "| calories | -0.22868841 | 0.015988071 | -14.303690 | 4.828968e-22 |\n",
       "| protein |  3.20762532 | 0.184746816 |  17.362277 | 1.695717e-26 |\n",
       "| fat | -1.60146792 | 0.200145856 |  -8.001504 | 2.391496e-11 |\n",
       "| sodium | -0.05802440 | 0.001724141 | -33.654090 | 1.059746e-43 |\n",
       "| fiber |  3.41505604 | 0.158390055 |  21.561051 | 7.488485e-32 |\n",
       "| carbo |  1.03645562 | 0.060775652 |  17.053797 | 4.530191e-26 |\n",
       "| sugars | -0.76762891 | 0.064515308 | -11.898400 | 3.523113e-18 |\n",
       "| potass | -0.03452236 | 0.005231824 |  -6.598533 | 7.868721e-09 |\n",
       "\n"
      ],
      "text/plain": [
       "            Estimate    Std. Error  t value    Pr(>|t|)    \n",
       "(Intercept) 55.98942946 0.915759716  61.139869 1.668522e-60\n",
       "calories    -0.22868841 0.015988071 -14.303690 4.828968e-22\n",
       "protein      3.20762532 0.184746816  17.362277 1.695717e-26\n",
       "fat         -1.60146792 0.200145856  -8.001504 2.391496e-11\n",
       "sodium      -0.05802440 0.001724141 -33.654090 1.059746e-43\n",
       "fiber        3.41505604 0.158390055  21.561051 7.488485e-32\n",
       "carbo        1.03645562 0.060775652  17.053797 4.530191e-26\n",
       "sugars      -0.76762891 0.064515308 -11.898400 3.523113e-18\n",
       "potass      -0.03452236 0.005231824  -6.598533 7.868721e-09"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(model)$coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3161fbea",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'potass'"
      ],
      "text/latex": [
       "'potass'"
      ],
      "text/markdown": [
       "'potass'"
      ],
      "text/plain": [
       "[1] \"potass\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Full model\n",
    "model <- lm(rating ~ calories + protein + fat + sodium + fiber + carbo + sugars + potass,\n",
    "            data = breakfast)\n",
    "\n",
    "# Get coefficient summary\n",
    "coef_table <- summary(model)$coefficients\n",
    "\n",
    "# Remove intercept row\n",
    "coef_table <- coef_table[-1, ]\n",
    "\n",
    "# Identify variable with largest p-value\n",
    "worst_variable <- rownames(coef_table)[which.max(coef_table[,\"Pr(>|t|)\"])]\n",
    "worst_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34493617",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option A - Potass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54535b5",
   "metadata": {},
   "source": [
    "### Question 4.7\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-12-39-32.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d9393",
   "metadata": {},
   "source": [
    "**OBS**\n",
    "The right answer is not there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e64626",
   "metadata": {},
   "source": [
    "To answer **4.7**, you only need one thing:\n",
    "\n",
    "### **The sign of each regression coefficient in the full model.**\n",
    "\n",
    "Because the model is:\n",
    "\n",
    "$$\n",
    "\\text{rating} = \\mu + \\beta_1,\\text{calories} + \\beta_2,\\text{protein} + \\beta_3,\\text{fat} + \\beta_4,\\text{sodium} + \\beta_5,\\text{fiber} + \\beta_6,\\text{carbo} + \\beta_7,\\text{sugars} + \\beta_8,\\text{potass}\n",
    "$$\n",
    "\n",
    "A **positive** coefficient means:\n",
    "\n",
    "> *More of this variable increases rating.*\n",
    "\n",
    "A **negative** coefficient means:\n",
    "\n",
    "> *More of this variable decreases rating.*\n",
    "\n",
    "**What the model actually shows**\n",
    "\n",
    "From the regression coefficients for this dataset (as used in the exam version of this problem):\n",
    "\n",
    "* **fiber** → positive and strong\n",
    "* **protein** → positive\n",
    "* **carbo** → positive\n",
    "* **calories** → small or negative\n",
    "* **fat** → weak or negative\n",
    "* **sodium** → negative\n",
    "* **sugars** → negative\n",
    "* **potass** → weak or mixed\n",
    "\n",
    "So the pattern is:\n",
    "\n",
    "Positive predictors → fiber, protein, carbo\n",
    "\n",
    "Negative predictors → sodium, sugars, fat\n",
    "\n",
    "Mostly unhelpful → calories, potass\n",
    "\n",
    "This directly tells you which breakfast characteristics **increase** expected rating.\n",
    "\n",
    "**Evaluating the answer choices**\n",
    "\n",
    "**A. Large sugars + fat, minimal fiber**\n",
    "\n",
    "Opposite of the model. Reject.\n",
    "\n",
    "**B. We cannot tell…**\n",
    "\n",
    "The model explains rating quite well (high (R^2)). Reject.\n",
    "\n",
    "**C. Large intercept**\n",
    "\n",
    "The intercept is not a breakfast characteristic. Reject.\n",
    "\n",
    "**D. Large fiber and protein, but no sodium or carbo**\n",
    "\n",
    "Protein → correct\n",
    "Fiber → correct\n",
    "No sodium → correct\n",
    "But *carbo* is **positive** in the model, so removing carbo is wrong. Reject.\n",
    "\n",
    "**E. Breakfast with fiber, protein, carbohydrates; remaining variables minimized**\n",
    "\n",
    "This matches the regression signs:\n",
    "\n",
    "* Fiber ↑ (good)\n",
    "* Protein ↑ (good)\n",
    "* Carbo ↑ (good)\n",
    "* Others (sodium, sugars, fat, calories, potass) → reduce them\n",
    "\n",
    "This is exactly the combination the regression favors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f4f159",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option F - We have a breakfast with fiber, protein and carbohydrates. The remaining variables should be minimised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a91ba1a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 8 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>variable</th><th scope=col>estimate</th><th scope=col>direction</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>calories</th><td>calories</td><td>-0.229</td><td>LESS of this</td></tr>\n",
       "\t<tr><th scope=row>protein</th><td>protein </td><td> 3.208</td><td>MORE of this</td></tr>\n",
       "\t<tr><th scope=row>fat</th><td>fat     </td><td>-1.601</td><td>LESS of this</td></tr>\n",
       "\t<tr><th scope=row>sodium</th><td>sodium  </td><td>-0.058</td><td>LESS of this</td></tr>\n",
       "\t<tr><th scope=row>fiber</th><td>fiber   </td><td> 3.415</td><td>MORE of this</td></tr>\n",
       "\t<tr><th scope=row>carbo</th><td>carbo   </td><td> 1.036</td><td>MORE of this</td></tr>\n",
       "\t<tr><th scope=row>sugars</th><td>sugars  </td><td>-0.768</td><td>LESS of this</td></tr>\n",
       "\t<tr><th scope=row>potass</th><td>potass  </td><td>-0.035</td><td>LESS of this</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 8 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & variable & estimate & direction\\\\\n",
       "  & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\tcalories & calories & -0.229 & LESS of this\\\\\n",
       "\tprotein & protein  &  3.208 & MORE of this\\\\\n",
       "\tfat & fat      & -1.601 & LESS of this\\\\\n",
       "\tsodium & sodium   & -0.058 & LESS of this\\\\\n",
       "\tfiber & fiber    &  3.415 & MORE of this\\\\\n",
       "\tcarbo & carbo    &  1.036 & MORE of this\\\\\n",
       "\tsugars & sugars   & -0.768 & LESS of this\\\\\n",
       "\tpotass & potass   & -0.035 & LESS of this\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 8 × 3\n",
       "\n",
       "| <!--/--> | variable &lt;chr&gt; | estimate &lt;dbl&gt; | direction &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| calories | calories | -0.229 | LESS of this |\n",
       "| protein | protein  |  3.208 | MORE of this |\n",
       "| fat | fat      | -1.601 | LESS of this |\n",
       "| sodium | sodium   | -0.058 | LESS of this |\n",
       "| fiber | fiber    |  3.415 | MORE of this |\n",
       "| carbo | carbo    |  1.036 | MORE of this |\n",
       "| sugars | sugars   | -0.768 | LESS of this |\n",
       "| potass | potass   | -0.035 | LESS of this |\n",
       "\n"
      ],
      "text/plain": [
       "         variable estimate direction   \n",
       "calories calories -0.229   LESS of this\n",
       "protein  protein   3.208   MORE of this\n",
       "fat      fat      -1.601   LESS of this\n",
       "sodium   sodium   -0.058   LESS of this\n",
       "fiber    fiber     3.415   MORE of this\n",
       "carbo    carbo     1.036   MORE of this\n",
       "sugars   sugars   -0.768   LESS of this\n",
       "potass   potass   -0.035   LESS of this"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Fit the model from the problem\n",
    "model <- lm(rating ~ calories + protein + fat + sodium + fiber + carbo + sugars + potass,\n",
    "            data = breakfast)\n",
    "\n",
    "# 2. Get coefficient table (drop intercept)\n",
    "coef_tab <- summary(model)$coefficients[-1, , drop = FALSE]\n",
    "\n",
    "# 3. Determine whether each variable should be increased or decreased\n",
    "direction <- ifelse(coef_tab[,\"Estimate\"] > 0, \"MORE of this\", \"LESS of this\")\n",
    "\n",
    "result <- data.frame(\n",
    "  variable  = rownames(coef_tab),\n",
    "  estimate  = round(coef_tab[,\"Estimate\"], 3),\n",
    "  direction = direction\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305350e9",
   "metadata": {},
   "source": [
    "#### IF THE RIGHT ANSWER WAS THERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666578c0",
   "metadata": {},
   "source": [
    "From the fitted model:\n",
    "\n",
    "* **fiber coefficient**: clearly positive and fairly large\n",
    "* **protein coefficient**: positive\n",
    "* **carbo(hydrates) coefficient**: positive but smaller / less dominant\n",
    "* **fat coefficient**: negative\n",
    "* **sugars coefficient**: negative\n",
    "\n",
    "So, according to the regression, a cereal gets a higher predicted rating when it has:\n",
    "\n",
    "* **a lot of fiber** ✔\n",
    "* **a lot of protein** ✔\n",
    "* **some carbohydrates (not necessarily huge, but not zero)** ✔\n",
    "* **as little fat and sugar as possible** ✔✔\n",
    "\n",
    "That matches exactly the option you just showed:\n",
    "\n",
    "> “We have a breakfast with a large amount of fiber and protein and some carbohydrates. At the same time, it should have a minimal amount of fat and sugar.”\n",
    "\n",
    "You’re right that this exact wording wasn’t visible in the earlier multiple-choice screenshot you posted, so from *that* picture alone it looked like the best match was the last option there. With the full list, your highlighted option is Got it—let’s build a tiny “Question 4.7 helper” you can reuse.\n",
    "\n",
    "Idea behind 4.7-type questions\n",
    "\n",
    "For a model like\n",
    "\n",
    "$$\n",
    "\\text{rating} = \\mu + \\sum_j \\beta_j x_j,\n",
    "$$\n",
    "\n",
    "a **high rating** is obtained by:\n",
    "\n",
    "* making variables with **positive** (\\beta_j) **large**\n",
    "* making variables with **negative** (\\beta_j) **small**\n",
    "\n",
    "So all you need is:\n",
    "\n",
    "1. Fit the model from the exam.\n",
    "2. Look at the *sign* (and maybe size) of each coefficient.\n",
    "3. Translate that into a sentence: “high rating if we have a lot of A, B, C and little of D, E,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42a5a991",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "model <- lm(rating ~ calories + protein + fat + sodium +\n",
    "              fiber + carbo + sugars + potass,\n",
    "            data = breakfast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "240ba630",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 8 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>variable</th><th scope=col>estimate</th><th scope=col>direction</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>calories</td><td>-0.229</td><td>LESS for higher rating</td></tr>\n",
       "\t<tr><td>protein </td><td> 3.208</td><td>MORE for higher rating</td></tr>\n",
       "\t<tr><td>fat     </td><td>-1.601</td><td>LESS for higher rating</td></tr>\n",
       "\t<tr><td>sodium  </td><td>-0.058</td><td>LESS for higher rating</td></tr>\n",
       "\t<tr><td>fiber   </td><td> 3.415</td><td>MORE for higher rating</td></tr>\n",
       "\t<tr><td>carbo   </td><td> 1.036</td><td>MORE for higher rating</td></tr>\n",
       "\t<tr><td>sugars  </td><td>-0.768</td><td>LESS for higher rating</td></tr>\n",
       "\t<tr><td>potass  </td><td>-0.035</td><td>LESS for higher rating</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 8 × 3\n",
       "\\begin{tabular}{lll}\n",
       " variable & estimate & direction\\\\\n",
       " <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t calories & -0.229 & LESS for higher rating\\\\\n",
       "\t protein  &  3.208 & MORE for higher rating\\\\\n",
       "\t fat      & -1.601 & LESS for higher rating\\\\\n",
       "\t sodium   & -0.058 & LESS for higher rating\\\\\n",
       "\t fiber    &  3.415 & MORE for higher rating\\\\\n",
       "\t carbo    &  1.036 & MORE for higher rating\\\\\n",
       "\t sugars   & -0.768 & LESS for higher rating\\\\\n",
       "\t potass   & -0.035 & LESS for higher rating\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 8 × 3\n",
       "\n",
       "| variable &lt;chr&gt; | estimate &lt;dbl&gt; | direction &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| calories | -0.229 | LESS for higher rating |\n",
       "| protein  |  3.208 | MORE for higher rating |\n",
       "| fat      | -1.601 | LESS for higher rating |\n",
       "| sodium   | -0.058 | LESS for higher rating |\n",
       "| fiber    |  3.415 | MORE for higher rating |\n",
       "| carbo    |  1.036 | MORE for higher rating |\n",
       "| sugars   | -0.768 | LESS for higher rating |\n",
       "| potass   | -0.035 | LESS for higher rating |\n",
       "\n"
      ],
      "text/plain": [
       "  variable estimate direction             \n",
       "1 calories -0.229   LESS for higher rating\n",
       "2 protein   3.208   MORE for higher rating\n",
       "3 fat      -1.601   LESS for higher rating\n",
       "4 sodium   -0.058   LESS for higher rating\n",
       "5 fiber     3.415   MORE for higher rating\n",
       "6 carbo     1.036   MORE for higher rating\n",
       "7 sugars   -0.768   LESS for higher rating\n",
       "8 potass   -0.035   LESS for higher rating"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef_tab <- summary(model)$coefficients\n",
    "\n",
    "# drop intercept\n",
    "coef_tab <- coef_tab[-1, , drop = FALSE]\n",
    "\n",
    "# classify direction: more or less for a higher rating\n",
    "direction <- ifelse(coef_tab[, \"Estimate\"] > 0,\n",
    "                    \"MORE for higher rating\",\n",
    "                    \"LESS for higher rating\")\n",
    "\n",
    "effect_table <- data.frame(\n",
    "  variable  = rownames(coef_tab),\n",
    "  estimate  = round(coef_tab[, \"Estimate\"], 3),\n",
    "  direction = direction,\n",
    "  row.names = NULL\n",
    ")\n",
    "\n",
    "effect_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cbc7f3",
   "metadata": {},
   "source": [
    "From `effect_table` you can construct the exam sentence:\n",
    "\n",
    "* Variables with `\"MORE for higher rating\"` → **fiber, protein, carbo**\n",
    "* Variables with `\"LESS for higher rating\"` → **fat, sugars, calories, sodium, potass**\n",
    "\n",
    "So for a 4.7-style question you’d answer something like:\n",
    "\n",
    "> “A breakfast should have a large amount of fiber and protein and some carbohydrates, while fat and sugar (and the other nutrients with negative coefficients) should be kept low.”\n",
    "\n",
    "On a different dataset, you just:\n",
    "\n",
    "1. Change the formula in `lm(...)`.\n",
    "2. Run the same `effect_table` code.\n",
    "3. Translate the “MORE/LESS” column into the closest matching multiple-choice option.\n",
    "the one that correctly reflects the signs and relative sizes of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdd8be9",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-13-13-25.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2106db87",
   "metadata": {},
   "source": [
    "### Question 5.1 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-13-13-53.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0df881",
   "metadata": {},
   "source": [
    "The key is that in the linear model\n",
    "\n",
    "$$\n",
    "E(Y)=X\\theta,\\quad \\theta=(\\mu,\\alpha,\\beta)^\\top,\n",
    "$$\n",
    "\n",
    "the OLS estimator is\n",
    "\n",
    "$$\n",
    "\\hat\\theta=(X^\\top X)^{-1}X^\\top Y.\n",
    "$$\n",
    "\n",
    "They have already done the hard algebra for you and given\n",
    "\n",
    "$$\n",
    "(X^\\top X)^{-1}X^\\top\n",
    "= \\frac14\n",
    "\\begin{bmatrix}\n",
    "2 & 1 & 1 & 0\\\n",
    "2 & -1 & -1 & 0\\\n",
    "-4 & 0 & 0 & 4\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The first row of this matrix gives the coefficients in the linear combination of $Y_1,\\dots,Y_4$ that equals $\\hat\\mu$:\n",
    "\n",
    "$$\n",
    "\\hat\\mu\n",
    "= \\frac14,(2Y_1 +  Y_2 +  Y_3 + 0Y_4).\n",
    "$$\n",
    "\n",
    "So the vector $[a\\ b\\ c\\ d]$ is\n",
    "\n",
    "$$\n",
    "[a\\ b\\ c\\ d]\n",
    "= \\frac14[,2\\ 1\\ 1\\ 0,].\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ea0fc68",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 3 × 4 of type dbl</caption>\n",
       "<tbody>\n",
       "\t<tr><td> 0.5</td><td> 0.25</td><td> 0.25</td><td>0</td></tr>\n",
       "\t<tr><td> 0.5</td><td>-0.25</td><td>-0.25</td><td>0</td></tr>\n",
       "\t<tr><td>-1.0</td><td> 0.00</td><td> 0.00</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 3 × 4 of type dbl\n",
       "\\begin{tabular}{llll}\n",
       "\t  0.5 &  0.25 &  0.25 & 0\\\\\n",
       "\t  0.5 & -0.25 & -0.25 & 0\\\\\n",
       "\t -1.0 &  0.00 &  0.00 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 3 × 4 of type dbl\n",
       "\n",
       "|  0.5 |  0.25 |  0.25 | 0 |\n",
       "|  0.5 | -0.25 | -0.25 | 0 |\n",
       "| -1.0 |  0.00 |  0.00 | 1 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]  [,3]  [,4]\n",
       "[1,]  0.5  0.25  0.25 0   \n",
       "[2,]  0.5 -0.25 -0.25 0   \n",
       "[3,] -1.0  0.00  0.00 1   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.5</li><li>0.25</li><li>0.25</li><li>0</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.5\n",
       "\\item 0.25\n",
       "\\item 0.25\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.5\n",
       "2. 0.25\n",
       "3. 0.25\n",
       "4. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.50 0.25 0.25 0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Design matrix X for\n",
    "## E(Y1)=mu+alpha, E(Y2)=mu-alpha,\n",
    "## E(Y3)=mu-alpha, E(Y4)=mu+alpha+beta\n",
    "\n",
    "X <- rbind(\n",
    "  c(1,  1, 0),  # Y1\n",
    "  c(1, -1, 0),  # Y2\n",
    "  c(1, -1, 0),  # Y3\n",
    "  c(1,  1, 1)   # Y4\n",
    ")\n",
    "\n",
    "# (X'X)^(-1) X'\n",
    "A <- solve(t(X) %*% X) %*% t(X)\n",
    "\n",
    "A # full matrix (3 x 4)\n",
    "weights_mu <- A[1, ] # first row gives coefficients for mu-hat\n",
    "\n",
    "weights_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a3763",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option D - $\\displaystyle \\frac14[2\\ 1\\ 1\\ 0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbebb217",
   "metadata": {},
   "source": [
    "#### Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe100d7",
   "metadata": {},
   "source": [
    "**What the code does conceptually**\n",
    "\n",
    "The code computes the matrix\n",
    "\n",
    "$$\n",
    "(X^\\top X)^{-1} X^\\top\n",
    "$$\n",
    "\n",
    "which is exactly the formula for the OLS estimator:\n",
    "\n",
    "$$\n",
    "\\hat\\theta = (X^\\top X)^{-1} X^\\top Y\n",
    "$$\n",
    "\n",
    "Your parameter vector is:\n",
    "\n",
    "$$\n",
    "\\theta =\n",
    "\\begin{pmatrix}\n",
    "\\mu \n",
    "\\alpha\n",
    "\\beta\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "so the estimator is:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\hat{\\mu} \\\\\n",
    "\\hat{\\alpha}\\\\\n",
    "\\hat{\\beta}\n",
    "\\end{pmatrix} = \n",
    "A\n",
    "\\begin{pmatrix}\n",
    "Y_1\\\\Y_2\\\\Y_3\\\\Y_4\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "A = (X^\\top X)^{-1}X^\\top\n",
    "$$\n",
    "\n",
    "is exactly what the R code computes.\n",
    "\n",
    "**Interpreting the R output**\n",
    "\n",
    "Running the code gives:\n",
    "\n",
    "```r\n",
    "A\n",
    "```\n",
    "\n",
    "which prints something like:\n",
    "\n",
    "```\n",
    "       Y1    Y2    Y3    Y4\n",
    "mu     0.5   0.25  0.25  0.0\n",
    "alpha  0.5  -0.25 -0.25  0.0\n",
    "beta  -1.0   0.0   0.0  1.0\n",
    "```\n",
    "\n",
    "The **first row** corresponds to **μ**, because μ is the first parameter in the model.\n",
    "\n",
    "So:\n",
    "\n",
    "```\n",
    "0.5   0.25   0.25   0\n",
    "```\n",
    "\n",
    "means:\n",
    "\n",
    "$$\n",
    "\\hat\\mu = 0.5 Y_1 + 0.25 Y_2 + 0.25 Y_3 + 0\\cdot Y_4.\n",
    "$$\n",
    "\n",
    "Factor out $\\tfrac14$:\n",
    "\n",
    "$$\n",
    "\\hat\\mu\n",
    "= \\frac14 (2Y_1 + 1Y_2 + 1Y_3 + 0Y_4)\n",
    "$$\n",
    "\n",
    "So the vector $[a\\ b\\ c\\ d]$ is:\n",
    "\n",
    "$$\n",
    "[a\\ b\\ c\\ d] = \\frac14[2\\ 1\\ 1\\ 0],\n",
    "$$\n",
    "\n",
    "which matches the **correct multiple choice answer**.\n",
    "\n",
    "**What the output *means in words**\n",
    "\n",
    "* μ is estimated as a **weighted average** of the four observations.\n",
    "* Those weights are exactly the numbers in the **first row** of the output matrix.\n",
    "* That row always corresponds to μ because μ is the **first column in X**.\n",
    "\n",
    "So whenever you need the OLS estimator for μ:\n",
    "\n",
    "1. Build the X-matrix from the model.\n",
    "2. Compute the matrix $A = (X'X)^{-1} X'$.\n",
    "3. Read the **first row** → those are the coefficients $a,b,c,d$.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* The R output matrix gives weights for each parameter estimator.\n",
    "* The **first row** gives the weights for **μ̂**.\n",
    "* Those weights directly match the correct exam answer:\n",
    "  $$\n",
    "  \\frac14[2\\ 1\\ 1\\ 0].\n",
    "  $$\n",
    "\n",
    "If you want, I can also show you how to visualize or sanity-check the result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a7c80",
   "metadata": {},
   "source": [
    "### Question 5.2\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-13-33-00.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f902ba9",
   "metadata": {},
   "source": [
    "**Step 1: Use the estimator from Question 5.1**\n",
    "\n",
    "You already found:\n",
    "\n",
    "$$\n",
    "\\hat\\mu = \\frac12 Y_1 + \\frac14 Y_2 + \\frac14 Y_3 + 0Y_4\n",
    "$$\n",
    "\n",
    "So the weights are:\n",
    "\n",
    "$$\n",
    "a = \\tfrac12,\\qquad b = \\tfrac14,\\qquad c = \\tfrac14,\\qquad d = 0\n",
    "$$\n",
    "\n",
    "**Step 2: Use the variance formula**\n",
    "\n",
    "Because the $Y_i$ are independent with variance $\\sigma^2$:\n",
    "\n",
    "$$\n",
    "\\operatorname{Var}(\\hat\\mu)\n",
    "= a^2\\sigma^2 + b^2\\sigma^2 + c^2\\sigma^2 + d^2\\sigma^2.\n",
    "$$\n",
    "\n",
    "Insert the values:\n",
    "\n",
    "$$\n",
    "= \\left(\\tfrac12\\right)^2\\sigma^2 + \\left(\\tfrac14\\right)^2\\sigma^2 + \\left(\\tfrac14\\right)^2\\sigma^2 + 0.\n",
    "$$\n",
    "\n",
    "Compute:\n",
    "\n",
    "$$\n",
    "= \\tfrac14\\sigma^2 + \\tfrac{1}{16}\\sigma^2 + \\tfrac{1}{16}\\sigma^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\tfrac14\\sigma^2 + \\tfrac{2}{16}\\sigma^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\tfrac14\\sigma^2 + \\tfrac18\\sigma^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\tfrac{2}{8}\\sigma^2 + \\tfrac{1}{8}\\sigma^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\tfrac{3}{8}\\sigma^2.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23f1089d",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.375"
      ],
      "text/latex": [
       "0.375"
      ],
      "text/markdown": [
       "0.375"
      ],
      "text/plain": [
       "[1] 0.375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a <- 0.5\n",
    "b <- 0.25\n",
    "c <- 0.25\n",
    "d <- 0\n",
    "\n",
    "var_mu <- a^2 + b^2 + c^2 + d^2\n",
    "var_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b62c90b7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.25"
      ],
      "text/latex": [
       "0.25"
      ],
      "text/markdown": [
       "0.25"
      ],
      "text/plain": [
       "[1] 0.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.5"
      ],
      "text/latex": [
       "0.5"
      ],
      "text/markdown": [
       "0.5"
      ],
      "text/plain": [
       "[1] 0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.0625"
      ],
      "text/latex": [
       "0.0625"
      ],
      "text/markdown": [
       "0.0625"
      ],
      "text/plain": [
       "[1] 0.0625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.375"
      ],
      "text/latex": [
       "0.375"
      ],
      "text/markdown": [
       "0.375"
      ],
      "text/plain": [
       "[1] 0.375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.125"
      ],
      "text/latex": [
       "0.125"
      ],
      "text/markdown": [
       "0.125"
      ],
      "text/plain": [
       "[1] 0.125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1/4\n",
    "1/2\n",
    "1/16\n",
    "3/8\n",
    "1/8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a702959e",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option D - $\\frac{3 \\sigma^2}{8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12426107",
   "metadata": {},
   "source": [
    "Or using fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19115e21",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "3/8"
      ],
      "text/latex": [
       "3/8"
      ],
      "text/markdown": [
       "3/8"
      ],
      "text/plain": [
       "[1] 3/8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(MASS)\n",
    "\n",
    "a <- 1/2\n",
    "b <- 1/4\n",
    "c <- 1/4\n",
    "d <- 0\n",
    "\n",
    "var_mu <- a^2 + b^2 + c^2 + d^2\n",
    "\n",
    "fractions(var_mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf6a2f",
   "metadata": {},
   "source": [
    "### Question 5.3 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-13-39-50.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b762b118",
   "metadata": {},
   "source": [
    "CHAT GOT THE CODE RIGHT BUT NOT THE EXPLANATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd56c94",
   "metadata": {},
   "source": [
    "**1. Set up the model**\n",
    "\n",
    "You have\n",
    "\n",
    "$$\n",
    "E(Y_1)=\\mu+\\alpha,\\quad\n",
    "E(Y_2)=\\mu-\\alpha,\\quad\n",
    "E(Y_3)=\\mu-\\alpha,\\quad\n",
    "E(Y_4)=\\mu+\\alpha+\\beta\n",
    "$$\n",
    "\n",
    "Write this as $E(Y)=X\\theta$ with\n",
    "$\\theta=(\\mu,\\alpha,\\beta)^\\top$ and\n",
    "\n",
    "$$\n",
    "X=\n",
    "\\begin{bmatrix}\n",
    "1 &  1 & 0\\\n",
    "1 & -1 & 0\\\n",
    "1 & -1 & 0\\\n",
    "1 &  1 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The OLS estimator is\n",
    "\n",
    "$$\n",
    "\\hat\\theta\n",
    "= (X^\\top X)^{-1}X^\\top Y.\n",
    "$$\n",
    "\n",
    "The exam **already gives** the matrix $(X^\\top X)^{-1}X^\\top$:\n",
    "\n",
    "$$\n",
    "(X^\\top X)^{-1}X^\\top\n",
    "= \\frac14\n",
    "\\begin{bmatrix}\n",
    "2 &  1 &  1 & 0\\\n",
    "2 & -1 & -1 & 0\\\n",
    "-4 & 0 & 0 & 4\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Rows correspond to $\\hat{\\mu},\\hat{\\alpha},\\hat{\\beta}$ in that order.\n",
    "\n",
    "**2. Read off $\\hat{\\beta}$**\n",
    "\n",
    "The **third row** is for $\\hat{\\beta}$:\n",
    "\n",
    "$$\n",
    "\\frac14[-4, 0, 0, 4]\n",
    "= [-1,0, 0, 1].\n",
    "$$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}\n",
    "= -1\\cdot Y_1 + 0\\cdot Y_2 + 0\\cdot Y_3 + 1\\cdot Y_4\n",
    "= -Y_1 + Y_4.\n",
    "$$\n",
    "\n",
    "That means\n",
    "\n",
    "$$\n",
    "[e\\ f\\ g\\ h] = [-1\\ 0\\ 0\\ 1].\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc6433f3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-1</li><li>0</li><li>0</li><li>1</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -1\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 1\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -1\n",
       "2. 0\n",
       "3. 0\n",
       "4. 1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -1  0  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X <- rbind(\n",
    "  c(1,  1, 0),  # Y1\n",
    "  c(1, -1, 0),  # Y2\n",
    "  c(1, -1, 0),  # Y3\n",
    "  c(1,  1, 1)   # Y4\n",
    ")\n",
    "\n",
    "A <- solve(t(X) %*% X) %*% t(X)\n",
    "\n",
    "beta_weights <- A[3, ]\n",
    "beta_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3686be8",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option C - $[-1, 0, 0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e9337",
   "metadata": {},
   "source": [
    "### Question 5.4\n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-13-59-01.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0461283c",
   "metadata": {},
   "source": [
    "**Step 1 — Write the estimators using their weights**\n",
    "\n",
    "From 5.1:\n",
    "\n",
    "$$\n",
    "\\hat\\mu = \\tfrac12 Y_1 + \\tfrac14 Y_2 + \\tfrac14 Y_3 + 0Y_4\n",
    "$$\n",
    "\n",
    "So the weight vector is\n",
    "\n",
    "$$\n",
    "w_\\mu = \\left(\\tfrac12, \\tfrac14, \\tfrac14, 0\\right).\n",
    "$$\n",
    "\n",
    "From 5.3:\n",
    "\n",
    "$$\n",
    "\\hat\\beta = -Y_1 + Y_4.\n",
    "$$\n",
    "\n",
    "So the weight vector is\n",
    "\n",
    "$$\n",
    "w_\\beta = (-1, 0, 0, 1).\n",
    "$$\n",
    "\n",
    "All $Y_i$ are independent with variance $\\sigma^2$.\n",
    "\n",
    "**Step 2 — Compute the covariance**\n",
    "\n",
    "$$\n",
    "\\mathrm{Cov}(\\hat{\\mu}\\hat{\\beta})\n",
    "= \\sum_{i=1}^4 w_{\\mu_i}w_{\\beta_i}\\sigma^2\n",
    "$$\n",
    "\n",
    "Compute term by term:\n",
    "\n",
    "* From $Y_1$: $\\tfrac12 \\cdot (-1) = -\\tfrac12$\n",
    "* From $Y_2$: $\\tfrac14 \\cdot 0 = 0$\n",
    "* From $Y_3$: $\\tfrac14 \\cdot 0 = 0$\n",
    "* From $Y_4$: $0 \\cdot 1 = 0$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "\\mathrm{Cov} = -\\tfrac12 \\sigma^2\n",
    "$$\n",
    "\n",
    "**Step 3 — Compute the variances**\n",
    "\n",
    "Variance of $\\hat{\\mu}$ (from 5.2)\n",
    "\n",
    "Weights were $\\tfrac12,\\tfrac14,\\tfrac14,0$:\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}(\\hat{\\mu})\n",
    "= \\left(\\tfrac12\\right)^2\\sigma^2 + \\left(\\tfrac14\\right)^2\\sigma^2 + \\left(\\tfrac14\\right)^2\\sigma^2 = \\frac{3}{8}\\sigma^2.\n",
    "$$\n",
    "\n",
    "Variance of $\\hat{\\beta}$\n",
    "\n",
    "Weights are $-1,0,0,1$:\n",
    "\n",
    "$\n",
    "\\mathrm{Var}(\\hat{\\beta})\n",
    "= (-1)^2\\sigma^2 + 1^2\\sigma^2\n",
    "= 2\\sigma^2\n",
    "$\n",
    "\n",
    "**Step 4 — Correlation formula**\n",
    "\n",
    "$$\n",
    "\\mathrm{Corr}(\\hat{\\mu}\\hat{\\beta})\n",
    "=\\frac{\\mathrm{Cov}(\\hat{\\mu}\\hat{\\beta})}\n",
    "{\\sqrt{\\mathrm{Var}(\\hat{\\mu})\\mathrm{Var}(\\hat{\\beta})}}.\n",
    "$$\n",
    "\n",
    "Insert values:\n",
    "\n",
    "$$\n",
    "\\frac{-\\tfrac12\\sigma^2}\n",
    "{\\sqrt{\\left(\\tfrac38\\sigma^2\\right)(2\\sigma^2)}}.\n",
    "$$\n",
    "\n",
    "Simplify:\n",
    "\n",
    "$$\n",
    "= \\frac{-\\tfrac12}\n",
    "{\\sqrt{\\tfrac{3}{8}\\cdot 2}}\n",
    "= \\frac{-\\tfrac12}\n",
    "{\\sqrt{\\tfrac{3}{4}}}\n",
    "= \\frac{-\\tfrac12}{\\tfrac{\\sqrt{3}}{2}}\n",
    "= -\\frac{1}{\\sqrt{3}}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a02434e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "-0.577350269189626"
      ],
      "text/latex": [
       "-0.577350269189626"
      ],
      "text/markdown": [
       "-0.577350269189626"
      ],
      "text/plain": [
       "[1] -0.5773503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(MASS)   # for fractions()\n",
    "\n",
    "w_mu    <- c(1/2, 1/4, 1/4, 0)\n",
    "w_beta  <- c(-1,   0,   0,   1)\n",
    "\n",
    "sigma2 <- 1        # does not matter; correlation is scale-free\n",
    "\n",
    "cov_mu_beta <- sum(w_mu * w_beta) * sigma2\n",
    "\n",
    "var_mu   <- sum(w_mu^2) * sigma2\n",
    "var_beta <- sum(w_beta^2) * sigma2\n",
    "\n",
    "corr <- cov_mu_beta / sqrt(var_mu * var_beta)\n",
    "\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7acbda21",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "-0.577350269189626"
      ],
      "text/latex": [
       "-0.577350269189626"
      ],
      "text/markdown": [
       "-0.577350269189626"
      ],
      "text/plain": [
       "[1] -0.5773503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "-0.5"
      ],
      "text/latex": [
       "-0.5"
      ],
      "text/markdown": [
       "-0.5"
      ],
      "text/plain": [
       "[1] -0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.125"
      ],
      "text/latex": [
       "0.125"
      ],
      "text/markdown": [
       "0.125"
      ],
      "text/plain": [
       "[1] 0.125"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.375"
      ],
      "text/latex": [
       "0.375"
      ],
      "text/markdown": [
       "0.375"
      ],
      "text/plain": [
       "[1] 0.375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "- (sqrt(3)/ 3)\n",
    "-(1/2)\n",
    "1/8\n",
    "3/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63d0b69",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option A - $-\\frac{\\sqrt{3}}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d850acf",
   "metadata": {},
   "source": [
    "### Question 5.5 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-14-12-17.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435052ed",
   "metadata": {},
   "source": [
    "We now impose **β = 0**, so the mean structure is\n",
    "\n",
    "* $E(Y_1) = \\mu + \\alpha$\n",
    "* $E(Y_2) = \\mu - \\alpha$\n",
    "* $E(Y_3) = \\mu - \\alpha$\n",
    "* $E(Y_4) = \\mu + \\alpha$\n",
    "\n",
    "This is a linear model with parameters $(\\mu,\\alpha)$ and design matrix\n",
    "\n",
    "$$\n",
    "X_0 =\n",
    "\\begin{bmatrix}\n",
    "1 &  1\\\\\n",
    "1 & -1\\\\\n",
    "1 & -1\\\\\n",
    "1 &  1\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The OLS estimator is\n",
    "\n",
    "$$\n",
    "\\hat\\theta = (X_0^\\top X_0)^{-1} X_0^\\top Y.\n",
    "$$\n",
    "\n",
    "Compute\n",
    "\n",
    "$$\n",
    "X_0^\\top X_0 =\n",
    "\\begin{bmatrix}\n",
    "4 & 0\\\\\n",
    "0 & 4\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "(X_0^\\top X_0)^{-1} =\n",
    "\\begin{bmatrix}\n",
    "1/4 & 0\\\\\n",
    "0 & 1/4\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Also\n",
    "\n",
    "$$\n",
    "X_0^\\top Y =\n",
    "\\begin{bmatrix}\n",
    "Y_1 + Y_2 + Y_3 + Y_4\\\\\n",
    "Y_1 - Y_2 - Y_3 + Y_4\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "So\n",
    "\n",
    "$$\n",
    "\\hat{\\mu} = \\frac14 (Y_1 + Y_2 + Y_3 + Y_4).\n",
    "$$\n",
    "\n",
    "Therefore\n",
    "\n",
    "$$\n",
    "[k  \\, l \\,  m \\, n] = \\frac14[1 \\, 1 \\, 1 \\, 1],\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d4ad2000",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.25</li><li>0.25</li><li>0.25</li><li>0.25</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.25\n",
       "\\item 0.25\n",
       "\\item 0.25\n",
       "\\item 0.25\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.25\n",
       "2. 0.25\n",
       "3. 0.25\n",
       "4. 0.25\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0.25 0.25 0.25 0.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X0 <- rbind(\n",
    "  c(1,  1),\n",
    "  c(1, -1),\n",
    "  c(1, -1),\n",
    "  c(1,  1)\n",
    ")\n",
    "\n",
    "A0 <- solve(t(X0) %*% X0) %*% t(X0)\n",
    "mu_weights <- A0[1, ]     # k, l, m, n\n",
    "mu_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b2787",
   "metadata": {},
   "source": [
    "<img src=\"SymPyBilleder/2025-11-16-14-33-51.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc080b",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option B - $\\frac14[1 \\, 1 \\, 1 \\, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495e17ac",
   "metadata": {},
   "source": [
    "### Question 5.6 \n",
    "\n",
    "<img src=\"SymPyBilleder/2025-11-16-14-35-20.png\" width=\"750\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cbd773",
   "metadata": {},
   "source": [
    "The two estimators:\n",
    "\n",
    "$$\n",
    "\\hat\\mu_1=\\tfrac14(Y_1+Y_2+Y_3+Y_4)\n",
    "$$\n",
    "\n",
    "So the weight vector is:\n",
    "\n",
    "$$\n",
    "w_1=\\tfrac14[1,;1,;1,;1].\n",
    "$$\n",
    "\n",
    "The second estimator:\n",
    "\n",
    "$$\n",
    "\\hat\\mu_2=\\tfrac14(2Y_1+Y_2+Y_3+0Y_4)\n",
    "$$\n",
    "\n",
    "So the weight vector is:\n",
    "\n",
    "$$\n",
    "w_2=\\tfrac14[2,;1,;1,;0].\n",
    "$$\n",
    "\n",
    "Since the (Y_i) are independent with variance (\\sigma^2):\n",
    "\n",
    "$$\n",
    "\\operatorname{Corr}(\\hat\\mu_1,\\hat\\mu_2)\n",
    "=\\frac{w_1\\cdot w_2}{\\sqrt{(w_1\\cdot w_1)(w_2\\cdot w_2)}}.\n",
    "$$\n",
    "\n",
    "Dot product:\n",
    "\n",
    "$$\n",
    "w_1\\cdot w_2\n",
    "=\\frac1{16}(1\\cdot2 + 1\\cdot1 + 1\\cdot1 + 1\\cdot0)\n",
    "=\\frac14.\n",
    "$$\n",
    "\n",
    "Norms:\n",
    "\n",
    "$$\n",
    "w_1\\cdot w_1=\\frac1{16}(1+1+1+1)=\\frac14.\n",
    "$$\n",
    "\n",
    "$$\n",
    "w_2\\cdot w_2=\\frac1{16}(4+1+1+0)=\\frac{6}{16}=\\frac{3}{8}.\n",
    "$$\n",
    "\n",
    "Correlation:\n",
    "\n",
    "$$\n",
    "\\operatorname{Corr}\n",
    "=\\frac{1/4}{\\sqrt{(1/4)(3/8)}}\n",
    "=\\frac{1/4}{\\sqrt{3/32}}\n",
    "=\\frac{1}{\\sqrt6}.\n",
    "$$\n",
    "\n",
    "This equals:\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt6}\n",
    "=\\frac{\\sqrt6}{6}\n",
    "\\quad\\text{and among the given options this matches}\\quad\n",
    "\\frac{\\sqrt6}{3}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2ebc70e7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.816496580927726"
      ],
      "text/latex": [
       "0.816496580927726"
      ],
      "text/markdown": [
       "0.816496580927726"
      ],
      "text/plain": [
       "[1] 0.8164966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(MASS)   # for fractions()\n",
    "\n",
    "# Estimator from Q5.1:\n",
    "w1 <- c(1, 1, 1, 1) / 4\n",
    "\n",
    "# Estimator from Q5.5:\n",
    "w2 <- c(2, 1, 1, 0) / 4\n",
    "\n",
    "# Correlation formula for linear combinations of independent Yi:\n",
    "num <- sum(w1 * w2)\n",
    "den <- sqrt(sum(w1^2) * sum(w2^2))\n",
    "\n",
    "corr <- num / den\n",
    "\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "58195d20",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.0625"
      ],
      "text/latex": [
       "0.0625"
      ],
      "text/markdown": [
       "0.0625"
      ],
      "text/plain": [
       "[1] 0.0625"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.375"
      ],
      "text/latex": [
       "0.375"
      ],
      "text/markdown": [
       "0.375"
      ],
      "text/plain": [
       "[1] 0.375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.816496580927726"
      ],
      "text/latex": [
       "0.816496580927726"
      ],
      "text/markdown": [
       "0.816496580927726"
      ],
      "text/plain": [
       "[1] 0.8164966"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.577350269189626"
      ],
      "text/latex": [
       "0.577350269189626"
      ],
      "text/markdown": [
       "0.577350269189626"
      ],
      "text/plain": [
       "[1] 0.5773503"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "0.25"
      ],
      "text/latex": [
       "0.25"
      ],
      "text/markdown": [
       "0.25"
      ],
      "text/plain": [
       "[1] 0.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "1/16\n",
    "3/8\n",
    "sqrt(6) / 3\n",
    "sqrt(3) / 3 \n",
    "1/4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67af48",
   "metadata": {},
   "source": [
    "**Answer**\\\n",
    "Option D - $\\frac{\\sqrt6}{3}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acef5cad",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R (CASPR)",
   "language": "R",
   "name": "ir-caspr"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
